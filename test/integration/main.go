package main

import (
	"context"
	"database/sql"
	"encoding/json"
	"fmt"
	"log"
	"os"
	"runtime"
	"strconv"
	"strings"
	"sync"
	"time"

	_ "github.com/go-sql-driver/mysql"
	_ "github.com/lib/pq"
	_ "github.com/mattn/go-sqlite3"
	"github.com/rushairer/batchsql"
	"github.com/rushairer/batchsql/drivers"
)

// ç¯å¢ƒå˜é‡è§£æè¾…åŠ©å‡½æ•°
func parseIntEnv(key string, defaultValue int) int {
	if value := os.Getenv(key); value != "" {
		if parsed, err := strconv.Atoi(value); err == nil {
			return parsed
		}
	}
	return defaultValue
}

func parseDurationEnv(key string, defaultValue time.Duration) time.Duration {
	if value := os.Getenv(key); value != "" {
		if parsed, err := time.ParseDuration(value); err == nil {
			return parsed
		}
	}
	return defaultValue
}

// TestConfig æµ‹è¯•é…ç½®
type TestConfig struct {
	TestDuration      time.Duration `json:"test_duration"`
	ConcurrentWorkers int           `json:"concurrent_workers"`
	RecordsPerWorker  int           `json:"records_per_worker"`
	BatchSize         uint32        `json:"batch_size"`
	BufferSize        uint32        `json:"buffer_size"`
	FlushInterval     time.Duration `json:"flush_interval"`
}

// TestResult æµ‹è¯•ç»“æœ
type TestResult struct {
	Database            string        `json:"database"`
	TestName            string        `json:"test_name"`
	Duration            time.Duration `json:"duration"`
	TotalRecords        int64         `json:"total_records"`         // æˆåŠŸæäº¤çš„è®°å½•æ•°
	ActualRecords       int64         `json:"actual_records"`        // æ•°æ®åº“ä¸­å®é™…çš„è®°å½•æ•°
	DataIntegrityRate   float64       `json:"data_integrity_rate"`   // æ•°æ®å®Œæ•´æ€§ç™¾åˆ†æ¯”
	DataIntegrityStatus string        `json:"data_integrity_status"` // æ•°æ®å®Œæ•´æ€§çŠ¶æ€æè¿°
	RecordsPerSecond    float64       `json:"records_per_second"`    // RPS (ä»…åœ¨æ•°æ®å®Œæ•´æ€§100%æ—¶æœ‰æ•ˆ)
	RPSValid            bool          `json:"rps_valid"`             // RPSæ˜¯å¦æœ‰æ•ˆ
	RPSNote             string        `json:"rps_note"`              // RPSè¯´æ˜
	ConcurrentWorkers   int           `json:"concurrent_workers"`
	TestParameters      TestParams    `json:"test_parameters"` // æµ‹è¯•å‚æ•°
	MemoryUsage         MemoryStats   `json:"memory_usage"`
	Errors              []string      `json:"errors"`
	Success             bool          `json:"success"`
}

// TestParams æµ‹è¯•å‚æ•°
type TestParams struct {
	BatchSize       uint32        `json:"batch_size"`
	BufferSize      uint32        `json:"buffer_size"`
	FlushInterval   time.Duration `json:"flush_interval"`
	ExpectedRecords int64         `json:"expected_records"`
	TestDuration    time.Duration `json:"test_duration"`
}

// MemoryStats å†…å­˜ç»Ÿè®¡
type MemoryStats struct {
	AllocMB      float64 `json:"alloc_mb"`
	TotalAllocMB float64 `json:"total_alloc_mb"`
	SysMB        float64 `json:"sys_mb"`
	NumGC        uint32  `json:"num_gc"`
}

// TestReport æµ‹è¯•æŠ¥å‘Š
type TestReport struct {
	Timestamp   time.Time    `json:"timestamp"`
	Environment string       `json:"environment"`
	GoVersion   string       `json:"go_version"`
	TestConfig  TestConfig   `json:"test_config"`
	Results     []TestResult `json:"results"`
	Summary     TestSummary  `json:"summary"`
}

// TestSummary æµ‹è¯•æ‘˜è¦
type TestSummary struct {
	TotalTests    int     `json:"total_tests"`
	PassedTests   int     `json:"passed_tests"`
	FailedTests   int     `json:"failed_tests"`
	TotalRecords  int64   `json:"total_records"`
	AverageRPS    float64 `json:"average_rps"`
	MaxRPS        float64 `json:"max_rps"`
	TotalDuration string  `json:"total_duration"`
}

func main() {
	log.Println("ğŸš€ Starting BatchSQL Integration Tests...")

	// åŠ è½½é…ç½®
	config := loadConfig()

	// åˆ›å»ºæµ‹è¯•æŠ¥å‘Š
	report := &TestReport{
		Timestamp:   time.Now(),
		Environment: "Docker Integration",
		GoVersion:   runtime.Version(),
		TestConfig:  config,
		Results:     []TestResult{},
	}

	startTime := time.Now()

	// è¿è¡Œ MySQL æµ‹è¯•
	if mysqlDSN := os.Getenv("MYSQL_DSN"); mysqlDSN != "" {
		log.Println("ğŸ“Š Running MySQL integration tests...")
		mysqlResults := runDatabaseTests("mysql", mysqlDSN, config)
		report.Results = append(report.Results, mysqlResults...)
	}

	// è¿è¡Œ PostgreSQL æµ‹è¯•
	if postgresDSN := os.Getenv("POSTGRES_DSN"); postgresDSN != "" {
		log.Println("ğŸ“Š Running PostgreSQL integration tests...")
		postgresResults := runDatabaseTests("postgres", postgresDSN, config)
		report.Results = append(report.Results, postgresResults...)
	}

	// è¿è¡Œ SQLite æµ‹è¯•
	if sqliteDSN := os.Getenv("SQLITE_DSN"); sqliteDSN != "" {
		log.Println("ğŸ“Š Running SQLite integration tests...")
		sqliteResults := runDatabaseTests("sqlite3", sqliteDSN, config)
		report.Results = append(report.Results, sqliteResults...)
	}

	// ç”Ÿæˆæ‘˜è¦
	report.Summary = generateSummary(report.Results, time.Since(startTime))

	// ä¿å­˜æŠ¥å‘Š
	saveReport(report)

	// è¾“å‡ºç»“æœ
	printSummary(report)

	// å¦‚æœæœ‰å¤±è´¥çš„æµ‹è¯•ï¼Œé€€å‡ºç ä¸º 1
	if report.Summary.FailedTests > 0 {
		os.Exit(1)
	}
}

func loadConfig() TestConfig {
	// ç»Ÿä¸€ä»ç¯å¢ƒå˜é‡è¯»å–é…ç½®ï¼Œdocker-composeä¸ºå”¯ä¸€é…ç½®æº
	config := TestConfig{
		TestDuration:      parseDurationEnv("TEST_DURATION", 1800*time.Second), // 30åˆ†é’Ÿé»˜è®¤
		ConcurrentWorkers: parseIntEnv("CONCURRENT_WORKERS", 10),
		RecordsPerWorker:  parseIntEnv("RECORDS_PER_WORKER", 2000),
		BatchSize:         uint32(parseIntEnv("BATCH_SIZE", 200)),
		BufferSize:        uint32(parseIntEnv("BUFFER_SIZE", 5000)),
		FlushInterval:     parseDurationEnv("FLUSH_INTERVAL", 100*time.Millisecond),
	}

	log.Printf("ğŸ“‹ Loaded Test Configuration:")
	log.Printf("   Test Duration: %v", config.TestDuration)
	log.Printf("   Concurrent Workers: %d", config.ConcurrentWorkers)
	log.Printf("   Records Per Worker: %d", config.RecordsPerWorker)
	log.Printf("   Batch Size: %d", config.BatchSize)
	log.Printf("   Buffer Size: %d", config.BufferSize)
	log.Printf("   Flush Interval: %v", config.FlushInterval)

	return config
}

func runDatabaseTests(dbType, dsn string, config TestConfig) []TestResult {
	var results []TestResult

	// è¿æ¥æ•°æ®åº“
	db, err := sql.Open(dbType, dsn)
	if err != nil {
		log.Printf("âŒ Failed to connect to %s: %v", dbType, err)
		return results
	}
	defer db.Close()

	// è®¾ç½®è¿æ¥æ± 
	db.SetMaxOpenConns(100)
	db.SetMaxIdleConns(50)
	db.SetConnMaxLifetime(time.Hour)

	// æµ‹è¯•è¿æ¥
	if err := db.Ping(); err != nil {
		log.Printf("âŒ Failed to ping %s: %v", dbType, err)
		return results
	}

	// åˆ›å»ºæµ‹è¯•è¡¨
	if err := createTestTables(db, dbType); err != nil {
		log.Printf("âŒ Failed to create test tables for %s: %v", dbType, err)
		return results
	}

	// è¿è¡Œä¸åŒçš„æµ‹è¯•åœºæ™¯
	testCases := []struct {
		name     string
		testFunc func(*sql.DB, string, TestConfig) TestResult
	}{
		{"High Throughput Test", runHighThroughputTest},
		{"Concurrent Workers Test", runConcurrentWorkersTest},
		{"Large Batch Test", runLargeBatchTest},
		{"Memory Pressure Test", runMemoryPressureTest},
		{"Long Duration Test", runLongDurationTest},
	}

	for _, tc := range testCases {
		// æ¯ä¸ªæµ‹è¯•å‰æ¸…ç†è¡¨æ•°æ®ï¼Œç¡®ä¿æµ‹è¯•ç‹¬ç«‹æ€§
		log.Printf("  ğŸ§¹ Clearing table before %s...", tc.name)
		if err := clearTestTable(db, dbType); err != nil {
			log.Printf("âŒ Failed to clear table before %s: %v", tc.name, err)
			// ç»§ç»­æ‰§è¡Œæµ‹è¯•ï¼Œä½†è®°å½•é”™è¯¯
		}

		log.Printf("  ğŸ”„ Running %s on %s...", tc.name, dbType)
		result := tc.testFunc(db, dbType, config)
		result.TestName = tc.name
		result.Database = dbType
		results = append(results, result)

		// æµ‹è¯•é—´éš”ï¼Œè®©ç³»ç»Ÿæ¢å¤
		time.Sleep(5 * time.Second)
	}

	return results
}

func createTestTables(db *sql.DB, dbType string) error {
	var createSQL string

	switch dbType {
	case "mysql":
		createSQL = `
		DROP TABLE IF EXISTS integration_test;
		CREATE TABLE integration_test (
			id BIGINT PRIMARY KEY,
			name VARCHAR(255) NOT NULL,
			email VARCHAR(255) NOT NULL,
			data TEXT,
			value DECIMAL(10,2),
			is_active BOOLEAN DEFAULT TRUE,
			created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
			INDEX idx_name (name),
			INDEX idx_email (email)
		) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4;
		`
	case "postgres":
		createSQL = `
		DROP TABLE IF EXISTS integration_test;
		CREATE TABLE integration_test (
			id BIGINT PRIMARY KEY,
			name VARCHAR(255) NOT NULL,
			email VARCHAR(255) NOT NULL,
			data TEXT,
			value DECIMAL(10,2),
			is_active BOOLEAN DEFAULT TRUE,
			created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
		);
		
		CREATE INDEX IF NOT EXISTS idx_name ON integration_test(name);
		CREATE INDEX IF NOT EXISTS idx_email ON integration_test(email);
		`
	case "sqlite3":
		createSQL = `
		DROP TABLE IF EXISTS integration_test;
		CREATE TABLE integration_test (
			id INTEGER PRIMARY KEY,
			name TEXT NOT NULL,
			email TEXT NOT NULL,
			data TEXT,
			value REAL,
			is_active INTEGER DEFAULT 1,
			created_at DATETIME DEFAULT CURRENT_TIMESTAMP
		);
		
		CREATE INDEX IF NOT EXISTS idx_name ON integration_test(name);
		CREATE INDEX IF NOT EXISTS idx_email ON integration_test(email);
		`
	}

	_, err := db.Exec(createSQL)
	return err
}

// éªŒè¯æ•°æ®åº“ä¸­çš„å®é™…è®°å½•æ•°
func getActualRecordCount(db *sql.DB) (int64, error) {
	var count int64
	err := db.QueryRow("SELECT COUNT(*) FROM integration_test").Scan(&count)
	return count, err
}

// å®‰å…¨è®¡ç®—å†…å­˜å·®å€¼ï¼Œé¿å…è´Ÿæ•°æº¢å‡º
func calculateMemoryDiffMB(after, before uint64) float64 {
	if after >= before {
		return float64(after-before) / 1024 / 1024
	}
	// å¦‚æœ after < beforeï¼ˆGCå›æ”¶äº†å†…å­˜ï¼‰ï¼Œè¿”å›0è€Œä¸æ˜¯è´Ÿæ•°
	return 0.0
}

// calculateDataIntegrity è®¡ç®—æ•°æ®å®Œæ•´æ€§çŠ¶æ€
func calculateDataIntegrity(submitted, actual int64) (rate float64, status string, rpsValid bool, rpsNote string) {
	if actual < 0 {
		return 0.0, "â“ æ— æ³•éªŒè¯", false, "æ— æ³•è·å–å®é™…è®°å½•æ•°ï¼ŒRPSæ— æ•ˆ"
	}

	if submitted == 0 {
		return 0.0, "âŒ æ— æäº¤è®°å½•", false, "æ— æäº¤è®°å½•ï¼ŒRPSæ— æ•ˆ"
	}

	rate = float64(actual) / float64(submitted) * 100.0

	if actual == submitted {
		return 100.0, "âœ… å®Œå…¨ä¸€è‡´", true, "æ•°æ®å®Œæ•´æ€§100%ï¼ŒRPSæœ‰æ•ˆ"
	} else if actual > submitted {
		return rate, fmt.Sprintf("âš ï¸ è¶…å‡ºé¢„æœŸ (+%dæ¡)", actual-submitted), false, "æ•°æ®è¶…å‡ºé¢„æœŸï¼ŒRPSæ— æ•ˆ"
	} else {
		lossCount := submitted - actual
		lossRate := float64(lossCount) / float64(submitted) * 100.0
		return rate, fmt.Sprintf("âŒ æ•°æ®ä¸¢å¤± (-%dæ¡, %.1f%%)", lossCount, lossRate), false, fmt.Sprintf("æ•°æ®ä¸¢å¤±%.1f%%ï¼ŒRPSæ— æ•ˆ", lossRate)
	}
}

// æ¸…ç†æµ‹è¯•è¡¨æ•°æ® - ä½¿ç”¨é«˜æ€§èƒ½çš„æ¸…ç†æ–¹å¼
func clearTestTable(db *sql.DB, dbType string) error {
	switch dbType {
	case "mysql":
		// MySQL ä½¿ç”¨ TRUNCATEï¼Œæ€§èƒ½æœ€ä½³
		_, err := db.Exec("TRUNCATE TABLE integration_test")
		return err
	case "postgres":
		// PostgreSQL ä½¿ç”¨ TRUNCATEï¼Œæ”¯æŒçº§è”
		_, err := db.Exec("TRUNCATE TABLE integration_test RESTART IDENTITY")
		return err
	case "sqlite3":
		// SQLite ä½¿ç”¨é‡å»ºè¡¨æ–¹å¼ï¼Œé¿å…é”å®šé—®é¢˜
		return clearSQLiteTableByRecreate(db)
	default:
		// å…œåº•æ–¹æ¡ˆ
		_, err := db.Exec("DELETE FROM integration_test")
		return err
	}
}

// clearSQLiteTableByRecreate SQLiteä¸“ç”¨çš„é‡å»ºè¡¨æ¸…ç†æ–¹å¼
func clearSQLiteTableByRecreate(db *sql.DB) error {
	// 1. åˆ é™¤è¡¨
	if _, err := db.Exec("DROP TABLE IF EXISTS integration_test"); err != nil {
		return fmt.Errorf("failed to drop table: %v", err)
	}

	// 2. é‡æ–°åˆ›å»ºè¡¨
	createSQL := `
	CREATE TABLE integration_test (
		id INTEGER PRIMARY KEY,
		name TEXT NOT NULL,
		email TEXT NOT NULL,
		data TEXT,
		value REAL,
		is_active INTEGER DEFAULT 1,
		created_at DATETIME DEFAULT CURRENT_TIMESTAMP
	)`

	if _, err := db.Exec(createSQL); err != nil {
		return fmt.Errorf("failed to create table: %v", err)
	}

	// 3. é‡æ–°åˆ›å»ºç´¢å¼•
	indexes := []string{
		"CREATE INDEX IF NOT EXISTS idx_name ON integration_test(name)",
		"CREATE INDEX IF NOT EXISTS idx_email ON integration_test(email)",
	}

	for _, indexSQL := range indexes {
		if _, err := db.Exec(indexSQL); err != nil {
			return fmt.Errorf("failed to create index: %v", err)
		}
	}

	log.Printf("  âœ… SQLite table recreated successfully")
	return nil
}

func runHighThroughputTest(db *sql.DB, dbType string, config TestConfig) TestResult {
	ctx := context.Background()

	var batchSQL *batchsql.BatchSQL
	switch dbType {
	case "mysql":
		batchSQL = batchsql.NewMySQLBatchSQL(ctx, db, batchsql.PipelineConfig{
			BufferSize:    config.BufferSize,
			FlushSize:     config.BatchSize,
			FlushInterval: config.FlushInterval,
		})
	case "postgres":
		batchSQL = batchsql.NewPostgreSQLBatchSQL(ctx, db, batchsql.PipelineConfig{
			BufferSize:    config.BufferSize,
			FlushSize:     config.BatchSize,
			FlushInterval: config.FlushInterval,
		})
	case "sqlite3":
		batchSQL = batchsql.NewSQLiteBatchSQL(ctx, db, batchsql.PipelineConfig{
			BufferSize:    config.BufferSize,
			FlushSize:     config.BatchSize,
			FlushInterval: config.FlushInterval,
		})
	}

	schema := batchsql.NewSchema("integration_test", drivers.ConflictIgnore,
		"id", "name", "email", "data", "value", "is_active", "created_at")

	startTime := time.Now()
	var recordCount int64
	var errors []string

	// è®°å½•åˆå§‹å†…å­˜
	var m1 runtime.MemStats
	runtime.GC()
	runtime.ReadMemStats(&m1)

	// é«˜ååé‡æµ‹è¯• - é™åˆ¶è®°å½•æ•°é‡é¿å…å†…å­˜æ³„æ¼
	testCtx, cancel := context.WithTimeout(ctx, config.TestDuration)
	defer cancel()

	maxRecords := int64(config.ConcurrentWorkers * config.RecordsPerWorker) // é™åˆ¶æœ€å¤§è®°å½•æ•°

	for i := int64(0); i < maxRecords; i++ {
		select {
		case <-testCtx.Done():
			goto TestComplete
		default:
			request := batchsql.NewRequest(schema).
				SetInt64("id", i).
				SetString("name", fmt.Sprintf("User_%d", i)).
				SetString("email", fmt.Sprintf("user_%d@example.com", i)).
				SetString("data", fmt.Sprintf("Data_%d", i)). // å‡å°‘å­—ç¬¦ä¸²é•¿åº¦
				SetFloat64("value", float64(i%10000)/100.0).
				SetBool("is_active", i%2 == 0).
				SetTime("created_at", time.Now())

			if err := batchSQL.Submit(testCtx, request); err != nil {
				errors = append(errors, err.Error())
				if len(errors) > 100 { // é™åˆ¶é”™è¯¯æ•°é‡
					break
				}
			} else {
				recordCount++
			}

			// å®šæœŸå¼ºåˆ¶GCï¼Œé¿å…å†…å­˜ç§¯ç´¯
			if i%1000 == 0 {
				runtime.GC()
			}
		}
	}

TestComplete:
	duration := time.Since(startTime)

	// ç­‰å¾…å¤„ç†å®Œæˆ
	time.Sleep(5 * time.Second)

	// è®°å½•æœ€ç»ˆå†…å­˜
	var m2 runtime.MemStats
	runtime.GC()
	runtime.ReadMemStats(&m2)

	// æŸ¥è¯¢æ•°æ®åº“ä¸­çš„å®é™…è®°å½•æ•°
	actualRecords, countErr := getActualRecordCount(db)
	if countErr != nil {
		errors = append(errors, fmt.Sprintf("Failed to count actual records: %v", countErr))
		actualRecords = -1 // æ ‡è®°ä¸ºæ— æ³•è·å–
	}

	// è®¡ç®—æ•°æ®å®Œæ•´æ€§
	dataIntegrityRate, integrityStatus, rpsValid, rpsNote := calculateDataIntegrity(recordCount, actualRecords)

	// åªæœ‰åœ¨æ•°æ®å®Œæ•´æ€§100%æ—¶æ‰è®¡ç®—æœ‰æ•ˆçš„RPS
	rps := 0.0
	if rpsValid && duration.Seconds() > 0 {
		rps = float64(recordCount) / duration.Seconds()
	}

	return TestResult{
		Duration:            duration,
		TotalRecords:        recordCount,
		ActualRecords:       actualRecords,
		DataIntegrityRate:   dataIntegrityRate,
		DataIntegrityStatus: integrityStatus,
		RecordsPerSecond:    rps,
		RPSValid:            rpsValid,
		RPSNote:             rpsNote,
		ConcurrentWorkers:   1,
		TestParameters: TestParams{
			BatchSize:       config.BatchSize,
			BufferSize:      config.BufferSize,
			FlushInterval:   config.FlushInterval,
			ExpectedRecords: int64(config.ConcurrentWorkers * config.RecordsPerWorker),
			TestDuration:    config.TestDuration,
		},
		MemoryUsage: MemoryStats{
			AllocMB:      calculateMemoryDiffMB(m2.Alloc, m1.Alloc),
			TotalAllocMB: calculateMemoryDiffMB(m2.TotalAlloc, m1.TotalAlloc),
			SysMB:        calculateMemoryDiffMB(m2.Sys, m1.Sys),
			NumGC:        m2.NumGC - m1.NumGC,
		},
		Errors:  errors,
		Success: len(errors) == 0 && rpsValid, // åªæœ‰æ•°æ®å®Œæ•´æ€§100%æ‰ç®—æˆåŠŸ
	}
}

func runConcurrentWorkersTest(db *sql.DB, dbType string, config TestConfig) TestResult {
	ctx := context.Background()

	var batchSQL *batchsql.BatchSQL
	switch dbType {
	case "mysql":
		batchSQL = batchsql.NewMySQLBatchSQL(ctx, db, batchsql.PipelineConfig{
			BufferSize:    config.BufferSize,
			FlushSize:     config.BatchSize,
			FlushInterval: config.FlushInterval,
		})
	case "postgres":
		batchSQL = batchsql.NewPostgreSQLBatchSQL(ctx, db, batchsql.PipelineConfig{
			BufferSize:    config.BufferSize,
			FlushSize:     config.BatchSize,
			FlushInterval: config.FlushInterval,
		})
	case "sqlite3":
		batchSQL = batchsql.NewSQLiteBatchSQL(ctx, db, batchsql.PipelineConfig{
			BufferSize:    config.BufferSize,
			FlushSize:     config.BatchSize,
			FlushInterval: config.FlushInterval,
		})
	}

	schema := batchsql.NewSchema("integration_test", drivers.ConflictIgnore,
		"id", "name", "email", "data", "value", "is_active", "created_at")

	startTime := time.Now()
	var totalRecords int64
	var mu sync.Mutex
	var errors []string

	// è®°å½•åˆå§‹å†…å­˜
	var m1 runtime.MemStats
	runtime.GC()
	runtime.ReadMemStats(&m1)

	// å¹¶å‘å·¥ä½œè€…æµ‹è¯• - æ‰¹æ¬¡å¤„ç†é¿å…å†…å­˜å³°å€¼
	var wg sync.WaitGroup
	batchSize := 100 // æ¯æ‰¹å¤„ç†100æ¡è®°å½•

	for workerID := 0; workerID < config.ConcurrentWorkers; workerID++ {
		wg.Add(1)
		go func(id int) {
			defer wg.Done()

			workerRecords := 0
			baseID := int64(id * config.RecordsPerWorker)

			// åˆ†æ‰¹å¤„ç†ï¼Œé¿å…å†…å­˜å³°å€¼
			for batch := 0; batch < config.RecordsPerWorker; batch += batchSize {
				endIdx := batch + batchSize
				if endIdx > config.RecordsPerWorker {
					endIdx = config.RecordsPerWorker
				}

				for i := batch; i < endIdx; i++ {
					request := batchsql.NewRequest(schema).
						SetInt64("id", baseID+int64(i)).
						SetString("name", fmt.Sprintf("W%d_U%d", id, i)).          // ç¼©çŸ­å­—ç¬¦ä¸²
						SetString("email", fmt.Sprintf("u%d_%d@test.com", id, i)). // ç¼©çŸ­å­—ç¬¦ä¸²
						SetString("data", fmt.Sprintf("D%d_%d", id, i)).           // å¤§å¹…ç¼©çŸ­æ•°æ®
						SetFloat64("value", float64((id*100+i)%1000)/10.0).
						SetBool("is_active", (id+i)%2 == 0).
						SetTime("created_at", time.Now())

					if err := batchSQL.Submit(ctx, request); err != nil {
						mu.Lock()
						errors = append(errors, fmt.Sprintf("Worker %d: %v", id, err))
						mu.Unlock()
					} else {
						workerRecords++
					}
				}

				// æ¯æ‰¹å¤„ç†å®Œåå¼ºåˆ¶GC
				runtime.GC()

				// æ·»åŠ å°å»¶è¿Ÿï¼Œé¿å…è¿‡åº¦ç«äº‰
				time.Sleep(10 * time.Millisecond)
			}

			mu.Lock()
			totalRecords += int64(workerRecords)
			mu.Unlock()
		}(workerID)
	}

	wg.Wait()
	duration := time.Since(startTime)

	// ç­‰å¾…å¤„ç†å®Œæˆ
	time.Sleep(5 * time.Second)

	// è®°å½•æœ€ç»ˆå†…å­˜
	var m2 runtime.MemStats
	runtime.GC()
	runtime.ReadMemStats(&m2)

	// æŸ¥è¯¢æ•°æ®åº“ä¸­çš„å®é™…è®°å½•æ•°
	actualRecords, countErr := getActualRecordCount(db)
	if countErr != nil {
		mu.Lock()
		errors = append(errors, fmt.Sprintf("Failed to count actual records: %v", countErr))
		mu.Unlock()
		actualRecords = -1 // æ ‡è®°ä¸ºæ— æ³•è·å–
	}

	// è®¡ç®—æ•°æ®å®Œæ•´æ€§
	dataIntegrityRate, integrityStatus, rpsValid, rpsNote := calculateDataIntegrity(totalRecords, actualRecords)

	// åªæœ‰åœ¨æ•°æ®å®Œæ•´æ€§100%æ—¶æ‰è®¡ç®—æœ‰æ•ˆçš„RPS
	rps := 0.0
	if rpsValid && duration.Seconds() > 0 {
		rps = float64(totalRecords) / duration.Seconds()
	}

	return TestResult{
		Duration:            duration,
		TotalRecords:        totalRecords,
		ActualRecords:       actualRecords,
		DataIntegrityRate:   dataIntegrityRate,
		DataIntegrityStatus: integrityStatus,
		RecordsPerSecond:    rps,
		RPSValid:            rpsValid,
		RPSNote:             rpsNote,
		ConcurrentWorkers:   config.ConcurrentWorkers,
		TestParameters: TestParams{
			BatchSize:       config.BatchSize,
			BufferSize:      config.BufferSize,
			FlushInterval:   config.FlushInterval,
			ExpectedRecords: int64(config.ConcurrentWorkers * config.RecordsPerWorker),
			TestDuration:    config.TestDuration,
		},
		MemoryUsage: MemoryStats{
			AllocMB:      calculateMemoryDiffMB(m2.Alloc, m1.Alloc),
			TotalAllocMB: calculateMemoryDiffMB(m2.TotalAlloc, m1.TotalAlloc),
			SysMB:        calculateMemoryDiffMB(m2.Sys, m1.Sys),
			NumGC:        m2.NumGC - m1.NumGC,
		},
		Errors:  errors,
		Success: len(errors) == 0 && rpsValid, // åªæœ‰æ•°æ®å®Œæ•´æ€§100%æ‰ç®—æˆåŠŸ
	}
}

func runLargeBatchTest(db *sql.DB, dbType string, config TestConfig) TestResult {
	// å¤§æ‰¹æ¬¡æµ‹è¯• - ä½¿ç”¨æ›´å¤§çš„æ‰¹æ¬¡å¤§å°
	largeConfig := config
	largeConfig.BatchSize = 5000
	largeConfig.BufferSize = 50000

	result := runHighThroughputTest(db, dbType, largeConfig)
	result.TestName = "Large Batch Test"
	return result
}

func runMemoryPressureTest(db *sql.DB, dbType string, config TestConfig) TestResult {
	// å†…å­˜å‹åŠ›æµ‹è¯• - ä½¿ç”¨å¤§æ•°æ®é‡å’Œå°æ‰¹æ¬¡
	memConfig := config
	memConfig.BatchSize = 100
	memConfig.BufferSize = 1000
	memConfig.RecordsPerWorker = 50000

	result := runConcurrentWorkersTest(db, dbType, memConfig)
	result.TestName = "Memory Pressure Test"
	return result
}

func runLongDurationTest(db *sql.DB, dbType string, config TestConfig) TestResult {
	// é•¿æ—¶é—´è¿è¡Œæµ‹è¯•
	longConfig := config
	longConfig.TestDuration = 10 * time.Minute

	result := runHighThroughputTest(db, dbType, longConfig)
	result.TestName = "Long Duration Test"
	return result
}

// getReportsDirectory æ™ºèƒ½æ£€æµ‹æŠ¥å‘Šç›®å½•ï¼Œå…¼å®¹æœ¬åœ°å’ŒDockerç¯å¢ƒ
func getReportsDirectory() string {
	// æ£€æŸ¥æ˜¯å¦åœ¨Dockerç¯å¢ƒä¸­ï¼ˆé€šè¿‡æ£€æŸ¥/appç›®å½•æ˜¯å¦å­˜åœ¨ä¸”å¯å†™ï¼‰
	if info, err := os.Stat("/app"); err == nil && info.IsDir() {
		// å°è¯•åœ¨/appç›®å½•åˆ›å»ºæµ‹è¯•æ–‡ä»¶æ¥æ£€æŸ¥å†™æƒé™
		testFile := "/app/.write_test"
		if file, err := os.Create(testFile); err == nil {
			file.Close()
			os.Remove(testFile)
			return "/app/reports" // Dockerç¯å¢ƒï¼Œä½¿ç”¨/app/reports
		}
	}

	// æœ¬åœ°ç¯å¢ƒæˆ–Dockerç¯å¢ƒæ— å†™æƒé™ï¼Œä½¿ç”¨ç›¸å¯¹è·¯å¾„
	return "reports"
}

func generateSummary(results []TestResult, totalDuration time.Duration) TestSummary {
	summary := TestSummary{
		TotalTests:    len(results),
		TotalDuration: totalDuration.String(),
	}

	var totalRecords int64
	var validRPSCount int
	var totalValidRPS float64
	maxRPS := 0.0

	for _, result := range results {
		if result.Success {
			summary.PassedTests++
		} else {
			summary.FailedTests++
		}

		totalRecords += result.TotalRecords

		// åªç»Ÿè®¡æœ‰æ•ˆçš„RPS
		if result.RPSValid {
			totalValidRPS += result.RecordsPerSecond
			validRPSCount++

			if result.RecordsPerSecond > maxRPS {
				maxRPS = result.RecordsPerSecond
			}
		}
	}

	summary.TotalRecords = totalRecords
	summary.MaxRPS = maxRPS
	if validRPSCount > 0 {
		summary.AverageRPS = totalValidRPS / float64(validRPSCount)
	} else {
		summary.AverageRPS = 0.0 // æ²¡æœ‰æœ‰æ•ˆçš„RPSæ•°æ®
	}

	return summary
}

func saveReport(report *TestReport) {
	// æ™ºèƒ½æ£€æµ‹æŠ¥å‘Šç›®å½• - å…¼å®¹æœ¬åœ°å’ŒDockerç¯å¢ƒ
	reportsDir := getReportsDirectory()
	if err := os.MkdirAll(reportsDir, 0o755); err != nil {
		log.Printf("âŒ Failed to create reports directory: %v", err)
		return
	}

	// ç”Ÿæˆæ–‡ä»¶å
	timestamp := report.Timestamp.Format("2006-01-02_15-04-05")
	filename := fmt.Sprintf("%s/integration_test_report_%s.json", reportsDir, timestamp)

	// ä¿å­˜ JSON æŠ¥å‘Š
	data, err := json.MarshalIndent(report, "", "  ")
	if err != nil {
		log.Printf("âŒ Failed to marshal report: %v", err)
		return
	}

	if err := os.WriteFile(filename, data, 0o644); err != nil {
		log.Printf("âŒ Failed to save report: %v", err)
		return
	}

	log.Printf("ğŸ“Š Test report saved to: %s", filename)

	// ç”Ÿæˆ HTML æŠ¥å‘Š
	generateHTMLReport(report, timestamp, reportsDir)
}

func generateHTMLReport(report *TestReport, timestamp string, reportsDir string) {
	htmlContent := fmt.Sprintf(`
<!DOCTYPE html>
<html lang="zh-CN">
<head>
    <meta charset="UTF-8">
    <title>BatchSQL é›†æˆæµ‹è¯•æŠ¥å‘Š</title>
    <style>
        body { font-family: "Microsoft YaHei", "SimHei", Arial, sans-serif; margin: 20px; }
        .header { background: #f4f4f4; padding: 20px; border-radius: 5px; }
        .summary { background: #e8f5e8; padding: 15px; margin: 20px 0; border-radius: 5px; }
        .failed { background: #ffe8e8; }
        .result { margin: 10px 0; padding: 15px; border: 1px solid #ddd; border-radius: 5px; }
        .success { border-left: 5px solid #4CAF50; }
        .error { border-left: 5px solid #f44336; }
        table { width: 100%%; border-collapse: collapse; margin: 10px 0; }
        th, td { padding: 8px; text-align: left; border-bottom: 1px solid #ddd; }
        th { background-color: #f2f2f2; }
        .metric { display: inline-block; margin: 10px; padding: 10px; background: #f9f9f9; border-radius: 3px; }
    </style>
</head>
<body>
    <div class="header">
        <h1>ğŸš€ BatchSQL é›†æˆæµ‹è¯•æŠ¥å‘Š</h1>
        <p><strong>æµ‹è¯•æ—¶é—´:</strong> %s</p>
        <p><strong>æµ‹è¯•ç¯å¢ƒ:</strong> %s</p>
        <p><strong>Go ç‰ˆæœ¬:</strong> %s</p>
    </div>

    <div class="summary %s">
        <h2>ğŸ“Š æµ‹è¯•æ‘˜è¦</h2>
        <div class="metric"><strong>æ€»æµ‹è¯•æ•°:</strong> %d</div>
        <div class="metric"><strong>é€šè¿‡:</strong> %d</div>
        <div class="metric"><strong>å¤±è´¥:</strong> %d</div>
        <div class="metric"><strong>æ€»è®°å½•æ•°:</strong> %d</div>
        <div class="metric"><strong>å¹³å‡ RPS:</strong> %.2f</div>
        <div class="metric"><strong>æœ€å¤§ RPS:</strong> %.2f</div>
        <div class="metric"><strong>æ€»è€—æ—¶:</strong> %s</div>
    </div>

    <h2>ğŸ“‹ æµ‹è¯•ç»“æœ</h2>
`,
		report.Timestamp.Format("2006-01-02 15:04:05"),
		report.Environment,
		report.GoVersion,
		func() string {
			if report.Summary.FailedTests > 0 {
				return "failed"
			}
			return ""
		}(),
		report.Summary.TotalTests,
		report.Summary.PassedTests,
		report.Summary.FailedTests,
		report.Summary.TotalRecords,
		report.Summary.AverageRPS,
		report.Summary.MaxRPS,
		report.Summary.TotalDuration,
	)

	for _, result := range report.Results {
		status := "success"
		statusIcon := "âœ…"
		if !result.Success {
			status = "error"
			statusIcon = "âŒ"
		}

		// ä½¿ç”¨æ–°çš„æ•°æ®å®Œæ•´æ€§çŠ¶æ€
		consistencyStatus := result.DataIntegrityStatus

		actualRecordsDisplay := "N/A"
		if result.ActualRecords >= 0 {
			actualRecordsDisplay = fmt.Sprintf("%d", result.ActualRecords)
		}

		// RPSæ˜¾ç¤ºé€»è¾‘
		rpsDisplay := ""
		if result.RPSValid {
			rpsDisplay = fmt.Sprintf("%.2f", result.RecordsPerSecond)
		} else {
			rpsDisplay = fmt.Sprintf("<s>%.2f</s> (æ— æ•ˆ)", result.RecordsPerSecond)
		}

		htmlContent += fmt.Sprintf(`
    <div class="result %s">
        <h3>%s %s - %s</h3>
        <table>
            <tr><th>æŒ‡æ ‡</th><th>æ•°å€¼</th></tr>
            <tr><td>æµ‹è¯•è€—æ—¶</td><td>%s</td></tr>
            <tr><td>æäº¤è®°å½•æ•°</td><td>%d</td></tr>
            <tr><td>æ•°æ®åº“å®é™…è®°å½•æ•°</td><td>%s</td></tr>
            <tr><td>æ•°æ®å®Œæ•´æ€§</td><td>%s (%.1f%%)</td></tr>
            <tr><td>æ¯ç§’è®°å½•æ•° (RPS)</td><td>%s</td></tr>
            <tr><td>RPSæœ‰æ•ˆæ€§</td><td>%s</td></tr>
            <tr><td>å¹¶å‘å·¥ä½œè€…æ•°</td><td>%d</td></tr>
            <tr><td>æ‰¹æ¬¡å¤§å°</td><td>%d</td></tr>
            <tr><td>ç¼“å†²åŒºå¤§å°</td><td>%d</td></tr>
            <tr><td>åˆ·æ–°é—´éš”</td><td>%s</td></tr>
            <tr><td>å†…å­˜åˆ†é… (MB)</td><td>%.2f</td></tr>
            <tr><td>æ€»å†…å­˜åˆ†é… (MB)</td><td>%.2f</td></tr>
            <tr><td>ç³»ç»Ÿå†…å­˜ (MB)</td><td>%.2f</td></tr>
            <tr><td>GC è¿è¡Œæ¬¡æ•°</td><td>%d</td></tr>
            <tr><td>é”™è¯¯æ•°é‡</td><td>%d</td></tr>
        </table>
`,
			status,
			statusIcon,
			result.Database,
			result.TestName,
			result.Duration.String(),
			result.TotalRecords,
			actualRecordsDisplay,
			consistencyStatus,
			result.DataIntegrityRate,
			rpsDisplay,
			result.RPSNote,
			result.ConcurrentWorkers,
			result.TestParameters.BatchSize,
			result.TestParameters.BufferSize,
			result.TestParameters.FlushInterval.String(),
			result.MemoryUsage.AllocMB,
			result.MemoryUsage.TotalAllocMB,
			result.MemoryUsage.SysMB,
			result.MemoryUsage.NumGC,
			len(result.Errors),
		)

		if len(result.Errors) > 0 {
			htmlContent += "<h4>é”™è¯¯ä¿¡æ¯:</h4><ul>"
			for i, err := range result.Errors {
				if i >= 10 { // åªæ˜¾ç¤ºå‰10ä¸ªé”™è¯¯
					htmlContent += fmt.Sprintf("<li>... è¿˜æœ‰ %d ä¸ªé”™è¯¯</li>", len(result.Errors)-10)
					break
				}
				htmlContent += fmt.Sprintf("<li>%s</li>", err)
			}
			htmlContent += "</ul>"
		}

		htmlContent += "</div>"
	}

	htmlContent += `
</body>
</html>`

	htmlFilename := fmt.Sprintf("%s/integration_test_report_%s.html", reportsDir, timestamp)
	if err := os.WriteFile(htmlFilename, []byte(htmlContent), 0o644); err != nil {
		log.Printf("âŒ Failed to save HTML report: %v", err)
		return
	}

	log.Printf("ğŸ“Š HTML report saved to: %s", htmlFilename)
}

func printSummary(report *TestReport) {
	fmt.Println("\n" + strings.Repeat("=", 80))
	fmt.Println("ğŸš€ BATCHSQL é›†æˆæµ‹è¯•æ€»ç»“")
	fmt.Println(strings.Repeat("=", 80))

	fmt.Printf("ğŸ“… æµ‹è¯•æ—¶é—´: %s\n", report.Timestamp.Format("2006-01-02 15:04:05"))
	fmt.Printf("ğŸŒ æµ‹è¯•ç¯å¢ƒ: %s\n", report.Environment)
	fmt.Printf("ğŸ”§ Go ç‰ˆæœ¬: %s\n", report.GoVersion)

	fmt.Println("\nğŸ“Š æ€»ä½“ç»“æœ:")
	fmt.Printf("   æ€»æµ‹è¯•æ•°: %d\n", report.Summary.TotalTests)
	fmt.Printf("   âœ… é€šè¿‡: %d\n", report.Summary.PassedTests)
	fmt.Printf("   âŒ å¤±è´¥: %d\n", report.Summary.FailedTests)
	fmt.Printf("   ğŸ“ˆ æ€»è®°å½•æ•°: %d\n", report.Summary.TotalRecords)
	fmt.Printf("   âš¡ å¹³å‡ RPS: %.2f\n", report.Summary.AverageRPS)
	fmt.Printf("   ğŸš€ æœ€å¤§ RPS: %.2f\n", report.Summary.MaxRPS)
	fmt.Printf("   â±ï¸  æ€»è€—æ—¶: %s\n", report.Summary.TotalDuration)

	fmt.Println("\nğŸ“‹ è¯¦ç»†ç»“æœ:")
	for _, result := range report.Results {
		status := "âœ…"
		if !result.Success {
			status = "âŒ"
		}

		// ä½¿ç”¨æ–°çš„æ•°æ®å®Œæ•´æ€§ä¿¡æ¯
		consistencyInfo := fmt.Sprintf(" | %s (%.1f%%)", result.DataIntegrityStatus, result.DataIntegrityRate)

		// RPSæ˜¾ç¤º
		rpsInfo := ""
		if result.RPSValid {
			rpsInfo = fmt.Sprintf("RPS: %.2f", result.RecordsPerSecond)
		} else {
			rpsInfo = fmt.Sprintf("RPS: ~~%.2f~~ (æ— æ•ˆ)", result.RecordsPerSecond)
		}

		fmt.Printf("   %s %s - %s\n", status, result.Database, result.TestName)
		fmt.Printf("      è€—æ—¶: %s | æäº¤: %d | %s | å·¥ä½œè€…: %d | é”™è¯¯: %d%s\n",
			result.Duration.String(),
			result.TotalRecords,
			rpsInfo,
			result.ConcurrentWorkers,
			len(result.Errors),
			consistencyInfo,
		)
	}

	fmt.Println("\n" + strings.Repeat("=", 80))

	if report.Summary.FailedTests > 0 {
		fmt.Println("âŒ éƒ¨åˆ†æµ‹è¯•å¤±è´¥ - è¯·æŸ¥çœ‹è¯¦ç»†æŠ¥å‘Šè·å–æ›´å¤šä¿¡æ¯")
	} else {
		fmt.Println("ğŸ‰ æ‰€æœ‰æµ‹è¯•é€šè¿‡ - BatchSQL è¿è¡ŒçŠ¶æ€ä¼˜ç§€ï¼")
	}

	fmt.Println(strings.Repeat("=", 80))
}
