package main

import (
	"context"
	"fmt"
	"log"
	"net/http"
	"sync"
	"time"

	"github.com/gin-gonic/gin"
	"github.com/prometheus/client_golang/prometheus"
	"github.com/prometheus/client_golang/prometheus/collectors"
	"github.com/prometheus/client_golang/prometheus/promhttp"
)

// PrometheusMetrics Prometheus æŒ‡æ ‡æ”¶é›†å™¨
type PrometheusMetrics struct {
	// è®¡æ•°å™¨æŒ‡æ ‡
	totalRecordsProcessed *prometheus.CounterVec
	totalTestsRun         *prometheus.CounterVec
	totalErrors           *prometheus.CounterVec

	// ç›´æ–¹å›¾æŒ‡æ ‡
	testDuration     *prometheus.HistogramVec
	recordsPerSecond *prometheus.HistogramVec
	batchProcessTime *prometheus.HistogramVec

	// ä»ªè¡¨ç›˜æŒ‡æ ‡
	currentRPS        *prometheus.GaugeVec
	memoryUsage       *prometheus.GaugeVec
	dataIntegrityRate *prometheus.GaugeVec
	concurrentWorkers *prometheus.GaugeVec
	activeConnections *prometheus.GaugeVec

	// æ–°å¢ï¼šä¸æ ¸å¿ƒåº“å¯¹é½çš„ Gauge
	executorConcurrency *prometheus.GaugeVec
	queueLength         *prometheus.GaugeVec
	inflightBatches     *prometheus.GaugeVec

	// æ–°å¢ï¼šä¸æ ¸å¿ƒåº“å¯¹é½çš„ Histogram
	enqueueLatency   *prometheus.HistogramVec
	assembleDuration *prometheus.HistogramVec
	executeDuration  *prometheus.HistogramVec
	batchSize        *prometheus.HistogramVec

	// æ‘˜è¦æŒ‡æ ‡
	responseTime *prometheus.SummaryVec

	registry *prometheus.Registry
	server   *http.Server
	mutex    sync.RWMutex
}

// NewPrometheusMetrics åˆ›å»º Prometheus æŒ‡æ ‡æ”¶é›†å™¨
func NewPrometheusMetrics() *PrometheusMetrics {
	registry := prometheus.NewRegistry()

	pm := &PrometheusMetrics{
		// è®¡æ•°å™¨æŒ‡æ ‡
		totalRecordsProcessed: prometheus.NewCounterVec(
			prometheus.CounterOpts{
				Name: "batchsql_records_processed_total",
				Help: "Total number of records processed by BatchSQL",
			},
			[]string{"database", "test_name", "status"},
		),

		totalTestsRun: prometheus.NewCounterVec(
			prometheus.CounterOpts{
				Name: "batchsql_tests_run_total",
				Help: "Total number of tests run",
			},
			[]string{"database", "test_name", "result"},
		),

		totalErrors: prometheus.NewCounterVec(
			prometheus.CounterOpts{
				Name: "batchsql_errors_total",
				Help: "Total number of errors encountered",
			},
			[]string{"database", "test_name", "error_type"},
		),

		// ç›´æ–¹å›¾æŒ‡æ ‡
		testDuration: prometheus.NewHistogramVec(
			prometheus.HistogramOpts{
				Name:    "batchsql_test_duration_seconds",
				Help:    "Duration of BatchSQL tests in seconds",
				Buckets: prometheus.ExponentialBuckets(0.1, 2, 10), // 0.1s to ~100s
			},
			[]string{"database", "test_name"},
		),

		recordsPerSecond: prometheus.NewHistogramVec(
			prometheus.HistogramOpts{
				Name:    "batchsql_records_per_second",
				Help:    "Records processed per second",
				Buckets: prometheus.ExponentialBuckets(1000, 2, 12), // 1K to ~4M RPS
			},
			[]string{"database", "test_name"},
		),

		batchProcessTime: prometheus.NewHistogramVec(
			prometheus.HistogramOpts{
				Name:    "batchsql_batch_process_duration_seconds",
				Help:    "Time taken to process a batch",
				Buckets: prometheus.ExponentialBuckets(0.001, 2, 15), // 1ms to ~32s
			},
			[]string{"database", "batch_size"},
		),

		// ä»ªè¡¨ç›˜æŒ‡æ ‡
		currentRPS: prometheus.NewGaugeVec(
			prometheus.GaugeOpts{
				Name: "batchsql_current_rps",
				Help: "Current records per second",
			},
			[]string{"database", "test_name"},
		),

		memoryUsage: prometheus.NewGaugeVec(
			prometheus.GaugeOpts{
				Name: "batchsql_memory_usage_mb",
				Help: "Memory usage in MB",
			},
			[]string{"database", "test_name", "type"}, // type: alloc, total_alloc, sys
		),

		dataIntegrityRate: prometheus.NewGaugeVec(
			prometheus.GaugeOpts{
				Name: "batchsql_data_integrity_rate",
				Help: "Data integrity rate (0-1 range, multiply by 100 for percentage display)",
			},
			[]string{"database", "test_name"},
		),

		concurrentWorkers: prometheus.NewGaugeVec(
			prometheus.GaugeOpts{
				Name: "batchsql_concurrent_workers",
				Help: "Number of concurrent workers",
			},
			[]string{"database", "test_name"},
		),

		activeConnections: prometheus.NewGaugeVec(
			prometheus.GaugeOpts{
				Name: "batchsql_active_connections",
				Help: "Number of active database connections",
			},
			[]string{"database"},
		),

		// æ–°å¢ï¼šæ ¸å¿ƒåº“å¯¹é½çš„ Gauge
		executorConcurrency: prometheus.NewGaugeVec(
			prometheus.GaugeOpts{
				Name: "batchsql_executor_concurrency",
				Help: "Current executor concurrency",
			},
			[]string{"database"},
		),
		queueLength: prometheus.NewGaugeVec(
			prometheus.GaugeOpts{
				Name: "batchsql_pipeline_queue_length",
				Help: "Current pipeline queue length",
			},
			[]string{"database"},
		),

		inflightBatches: prometheus.NewGaugeVec(
			prometheus.GaugeOpts{
				Name: "batchsql_inflight_batches",
				Help: "Current in-flight batch count (executing now)",
			},
			[]string{"database"},
		),

		// æ–°å¢ï¼šæ ¸å¿ƒåº“å¯¹é½çš„ Histogram
		enqueueLatency: prometheus.NewHistogramVec(
			prometheus.HistogramOpts{
				Name:    "batchsql_enqueue_latency_seconds",
				Help:    "Latency from submit to enqueue",
				Buckets: prometheus.ExponentialBuckets(0.0005, 2, 18),
			},
			[]string{"database"},
		),
		assembleDuration: prometheus.NewHistogramVec(
			prometheus.HistogramOpts{
				Name:    "batchsql_batch_assemble_duration_seconds",
				Help:    "Duration to assemble a batch",
				Buckets: prometheus.ExponentialBuckets(0.0005, 2, 18),
			},
			[]string{"database"},
		),
		executeDuration: prometheus.NewHistogramVec(
			prometheus.HistogramOpts{
				Name:    "batchsql_execute_duration_seconds",
				Help:    "Execute duration for a batch",
				Buckets: prometheus.ExponentialBuckets(0.0005, 2, 18),
			},
			[]string{"database", "test_name"}, // ä¿å®ˆå¤ç”¨ç°æœ‰æ ‡ç­¾é›†ï¼Œè‹¥éœ€ table/status å¯åç»­æ‰©å±•
		),
		batchSize: prometheus.NewHistogramVec(
			prometheus.HistogramOpts{
				Name:    "batchsql_batch_size",
				Help:    "Batch size distribution",
				Buckets: prometheus.ExponentialBuckets(1, 2, 12),
			},
			[]string{"database"},
		),

		// æ‘˜è¦æŒ‡æ ‡
		responseTime: prometheus.NewSummaryVec(
			prometheus.SummaryOpts{
				Name:       "batchsql_response_time_seconds",
				Help:       "Response time for batch operations",
				Objectives: map[float64]float64{0.5: 0.05, 0.9: 0.01, 0.99: 0.001},
			},
			[]string{"database", "operation"},
		),

		registry: registry,
	}

	// æ³¨å†Œæ‰€æœ‰æŒ‡æ ‡
	registry.MustRegister(
		pm.totalRecordsProcessed,
		pm.totalTestsRun,
		pm.totalErrors,
		pm.testDuration,
		pm.recordsPerSecond,
		pm.batchProcessTime,
		// æ³¨å†Œæ–°å¢ç›´æ–¹å›¾
		pm.enqueueLatency,
		pm.assembleDuration,
		pm.executeDuration,
		pm.batchSize,
		// æ—¢æœ‰ä¸æ–°å¢ Gauge
		pm.currentRPS,
		pm.memoryUsage,
		pm.dataIntegrityRate,
		pm.concurrentWorkers,
		pm.activeConnections,
		pm.executorConcurrency,
		pm.queueLength,
		pm.inflightBatches,
		pm.responseTime,
	)

	// åˆå§‹åŒ–åŸºç¡€æŒ‡æ ‡ï¼Œç¡®ä¿ç«¯ç‚¹å§‹ç»ˆè¿”å›æœ‰æ•ˆæ•°æ®
	pm.initializeBaseMetrics()

	return pm
}

// StartServer å¯åŠ¨ Prometheus HTTP æœåŠ¡å™¨
func (pm *PrometheusMetrics) StartServer(port int) error {
	pm.mutex.Lock()
	defer pm.mutex.Unlock()

	if pm.server != nil {
		return fmt.Errorf("prometheus server already running")
	}

	// è®¾ç½® Gin ä¸ºå‘å¸ƒæ¨¡å¼ï¼Œå‡å°‘æ—¥å¿—è¾“å‡º
	gin.SetMode(gin.ReleaseMode)

	// åˆ›å»º Gin è·¯ç”±å™¨
	router := gin.Default()

	// æ·»åŠ  Go è¿è¡Œæ—¶æŒ‡æ ‡åˆ°æˆ‘ä»¬çš„è‡ªå®šä¹‰ registry
	pm.registry.MustRegister(collectors.NewBuildInfoCollector())
	pm.registry.MustRegister(collectors.NewGoCollector())
	pm.registry.MustRegister(collectors.NewProcessCollector(collectors.ProcessCollectorOpts{}))

	// åˆ›å»ºä½¿ç”¨æˆ‘ä»¬è‡ªå®šä¹‰ registry çš„ handler
	metricsHandler := promhttp.HandlerFor(pm.registry, promhttp.HandlerOpts{
		EnableOpenMetrics: false,
	})

	// æ·»åŠ  /metrics ç«¯ç‚¹
	router.GET("/metrics", gin.WrapH(metricsHandler))

	// æ·»åŠ å¥åº·æ£€æŸ¥ç«¯ç‚¹
	router.GET("/health", func(c *gin.Context) {
		c.String(http.StatusOK, "OK")
	})

	pm.server = &http.Server{
		Addr:    fmt.Sprintf(":%d", port),
		Handler: router,
	}

	go func() {
		log.Printf("ğŸ“Š Prometheus metrics server starting on port %d", port)
		log.Printf("ğŸ“Š Metrics endpoint: http://localhost:%d/metrics", port)
		if err := pm.server.ListenAndServe(); err != nil && err != http.ErrServerClosed {
			log.Printf("âŒ Prometheus server error: %v", err)
		}
	}()

	// ç­‰å¾…æœåŠ¡å™¨å¯åŠ¨
	time.Sleep(100 * time.Millisecond)
	return nil
}

// StopServer åœæ­¢ Prometheus HTTP æœåŠ¡å™¨
func (pm *PrometheusMetrics) StopServer() error {
	pm.mutex.Lock()
	defer pm.mutex.Unlock()

	if pm.server == nil {
		return nil
	}

	ctx, cancel := context.WithTimeout(context.Background(), 5*time.Second)
	defer cancel()

	err := pm.server.Shutdown(ctx)
	pm.server = nil

	if err == nil {
		log.Println("ğŸ“Š Prometheus metrics server stopped")
	}

	return err
}

// RecordTestResult è®°å½•æµ‹è¯•ç»“æœ
func (pm *PrometheusMetrics) RecordTestResult(result TestResult) {
	database := result.Database
	testName := result.TestName

	// è®°å½•æµ‹è¯•è¿è¡Œ
	if result.Success {
		pm.totalTestsRun.WithLabelValues(database, testName, "success").Inc()
	} else {
		pm.totalTestsRun.WithLabelValues(database, testName, "failure").Inc()
	}

	// è®°å½•å¤„ç†çš„è®°å½•æ•° (ç¡®ä¿å€¼ä¸ºæ­£æ•°)
	if result.TotalRecords > 0 {
		pm.totalRecordsProcessed.WithLabelValues(database, testName, "processed").Add(float64(result.TotalRecords))
	}
	if result.ActualRecords > 0 {
		pm.totalRecordsProcessed.WithLabelValues(database, testName, "actual").Add(float64(result.ActualRecords))
	}

	// è®°å½•é”™è¯¯
	if len(result.Errors) > 0 {
		for _, err := range result.Errors {
			pm.totalErrors.WithLabelValues(database, testName, "general").Inc()
			log.Printf("ğŸ“Š Recorded error for %s/%s: %s", database, testName, err)
		}
	}

	// è®°å½•æµ‹è¯•æŒç»­æ—¶é—´
	pm.testDuration.WithLabelValues(database, testName).Observe(result.Duration.Seconds())

	// è®°å½• RPSï¼ˆå¦‚æœæœ‰æ•ˆï¼‰
	if result.RPSValid && result.RecordsPerSecond > 0 {
		pm.recordsPerSecond.WithLabelValues(database, testName).Observe(result.RecordsPerSecond)
		pm.currentRPS.WithLabelValues(database, testName).Set(result.RecordsPerSecond)
	}

	// è®°å½•å†…å­˜ä½¿ç”¨æƒ…å†µ
	pm.memoryUsage.WithLabelValues(database, testName, "alloc").Set(result.MemoryUsage.AllocMB)
	pm.memoryUsage.WithLabelValues(database, testName, "total_alloc").Set(result.MemoryUsage.TotalAllocMB)
	pm.memoryUsage.WithLabelValues(database, testName, "sys").Set(result.MemoryUsage.SysMB)

	// è®°å½•æ•°æ®å®Œæ•´æ€§ (ç¡®ä¿å€¼åœ¨ 0-1 èŒƒå›´å†…)
	integrityRate := result.DataIntegrityRate / 100.0 // å°†ç™¾åˆ†æ¯”è½¬æ¢ä¸º 0-1 èŒƒå›´
	pm.dataIntegrityRate.WithLabelValues(database, testName).Set(integrityRate)

	// è®°å½•å¹¶å‘å·¥ä½œçº¿ç¨‹æ•°
	pm.concurrentWorkers.WithLabelValues(database, testName).Set(float64(result.ConcurrentWorkers))

	log.Printf("ğŸ“Š Recorded metrics for %s/%s: RPS=%.2f, Integrity=%.2f%%, Duration=%v",
		database, testName, result.RecordsPerSecond, result.DataIntegrityRate, result.Duration)
}

// RecordBatchProcessTime è®°å½•æ‰¹å¤„ç†æ—¶é—´
func (pm *PrometheusMetrics) RecordBatchProcessTime(database string, batchSize uint32, duration time.Duration) {
	pm.batchProcessTime.WithLabelValues(database, fmt.Sprintf("%d", batchSize)).Observe(duration.Seconds())
}

// RecordResponseTime è®°å½•å“åº”æ—¶é—´
func (pm *PrometheusMetrics) RecordResponseTime(database, operation string, duration time.Duration) {
	pm.responseTime.WithLabelValues(database, operation).Observe(duration.Seconds())
}

// æ–°å¢ï¼šä¸ MetricsReporter å¯¹é½çš„æ–¹æ³•
func (pm *PrometheusMetrics) RecordEnqueueLatency(database string, d time.Duration) {
	pm.enqueueLatency.WithLabelValues(database).Observe(d.Seconds())
}

func (pm *PrometheusMetrics) RecordAssembleDuration(database string, d time.Duration) {
	pm.assembleDuration.WithLabelValues(database).Observe(d.Seconds())
}

func (pm *PrometheusMetrics) RecordExecuteDuration(database, tableOrTest, status string, d time.Duration) {
	// ç›®å‰ prometheus.go ä¸­ executeDuration ä»…æœ‰ database,test_name ä¸¤ä¸ªæ ‡ç­¾
	// ä¸ºä¸ç ´åç°æœ‰é›†æˆæµ‹è¯•ç»“æ„ï¼Œè¿™é‡Œå°† tableOrTest ä½œä¸º test_name ä½¿ç”¨ï¼›status æš‚ä¸å…¥æ ‡ç­¾
	pm.executeDuration.WithLabelValues(database, tableOrTest).Observe(d.Seconds())
}

func (pm *PrometheusMetrics) RecordBatchSize(database string, n int) {
	pm.batchSize.WithLabelValues(database).Observe(float64(n))
}

func (pm *PrometheusMetrics) SetExecutorConcurrency(database string, n int) {
	pm.executorConcurrency.WithLabelValues(database).Set(float64(n))
}

func (pm *PrometheusMetrics) SetQueueLength(database string, n int) {
	pm.queueLength.WithLabelValues(database).Set(float64(n))
}

func (pm *PrometheusMetrics) IncInflight(database string) {
	pm.inflightBatches.WithLabelValues(database).Inc()
}

func (pm *PrometheusMetrics) DecInflight(database string) {
	pm.inflightBatches.WithLabelValues(database).Dec()
}

// initializeBaseMetrics åˆå§‹åŒ–åŸºç¡€æŒ‡æ ‡ï¼Œç¡®ä¿ç«¯ç‚¹å§‹ç»ˆè¿”å›æœ‰æ•ˆæ•°æ®
func (pm *PrometheusMetrics) initializeBaseMetrics() {
	// åˆå§‹åŒ–è®¡æ•°å™¨æŒ‡æ ‡ä¸º 0
	databases := []string{"mysql", "postgres", "sqlite", "redis"}
	testTypes := []string{"batch_insert", "concurrent_workers", "large_batch", "stress_test"}

	for _, db := range databases {
		for _, testType := range testTypes {
			// åˆå§‹åŒ–è®¡æ•°å™¨ - 3ä¸ªæ ‡ç­¾: database, test_name, status/result/error_type
			// ä½¿ç”¨ä¸ RecordTestResult ä¸­ç›¸åŒçš„æ ‡ç­¾å€¼
			pm.totalRecordsProcessed.WithLabelValues(db, testType, "processed").Add(0)
			pm.totalRecordsProcessed.WithLabelValues(db, testType, "actual").Add(0)
			pm.totalTestsRun.WithLabelValues(db, testType, "success").Add(0)
			pm.totalTestsRun.WithLabelValues(db, testType, "failure").Add(0)
			pm.totalErrors.WithLabelValues(db, testType, "general").Add(0)

			// åˆå§‹åŒ–ä»ªè¡¨ç›˜æŒ‡æ ‡ - æ ‡ç­¾æ•°é‡è¦åŒ¹é…å®šä¹‰
			// currentRPS: 2ä¸ªæ ‡ç­¾ (database, test_name)
			pm.currentRPS.WithLabelValues(db, testType).Set(0)

			// memoryUsage: 3ä¸ªæ ‡ç­¾ (database, test_name, type)
			pm.memoryUsage.WithLabelValues(db, testType, "alloc").Set(0)
			pm.memoryUsage.WithLabelValues(db, testType, "total_alloc").Set(0)
			pm.memoryUsage.WithLabelValues(db, testType, "sys").Set(0)

			// dataIntegrityRate: 2ä¸ªæ ‡ç­¾ (database, test_name) - èŒƒå›´ 0-1
			pm.dataIntegrityRate.WithLabelValues(db, testType).Set(1.0)

			// concurrentWorkers: 2ä¸ªæ ‡ç­¾ (database, test_name)
			pm.concurrentWorkers.WithLabelValues(db, testType).Set(0)
		}

		// activeConnections: 1ä¸ªæ ‡ç­¾ (database)
		pm.activeConnections.WithLabelValues(db).Set(0)
	}
}

// UpdateActiveConnections æ›´æ–°æ´»è·ƒè¿æ¥æ•°
func (pm *PrometheusMetrics) UpdateActiveConnections(database string, count int) {
	pm.activeConnections.WithLabelValues(database).Set(float64(count))
}

// UpdateCurrentRPS æ›´æ–°å½“å‰ RPS
func (pm *PrometheusMetrics) UpdateCurrentRPS(database, testName string, rps float64) {
	pm.currentRPS.WithLabelValues(database, testName).Set(rps)
}

// UpdateMemoryUsage æ›´æ–°å†…å­˜ä½¿ç”¨æƒ…å†µ
func (pm *PrometheusMetrics) UpdateMemoryUsage(database, testName string, allocMB, totalAllocMB, sysMB float64) {
	pm.memoryUsage.WithLabelValues(database, testName, "alloc").Set(allocMB)
	pm.memoryUsage.WithLabelValues(database, testName, "total_alloc").Set(totalAllocMB)
	pm.memoryUsage.WithLabelValues(database, testName, "sys").Set(sysMB)
}

// GetMetricsURL è·å–æŒ‡æ ‡ URL
func (pm *PrometheusMetrics) GetMetricsURL(port int) string {
	return fmt.Sprintf("http://localhost:%d/metrics", port)
}
