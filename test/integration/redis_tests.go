package main

import (
	"context"
	"fmt"
	"log"
	"runtime"
	"sync"
	"time"

	"github.com/redis/go-redis/v9"
	"github.com/rushairer/batchsql"
)

// runRedisTests è¿è¡Œ Redis æ•°æ®åº“æµ‹è¯•
func runRedisTests(dsn string, config TestConfig, prometheusMetrics *PrometheusMetrics) []TestResult {
	var results []TestResult

	// è§£æ Redis DSN
	opt, err := redis.ParseURL(dsn)
	if err != nil {
		log.Printf("âŒ è§£æ Redis DSN å¤±è´¥ï¼š%v", err)
		return results
	}

	// è¿æ¥ Redis
	rdb := redis.NewClient(opt)
	defer rdb.Close()

	// æµ‹è¯•è¿æ¥
	ctx := context.Background()
	if err := rdb.Ping(ctx).Err(); err != nil {
		log.Printf("âŒ Ping Redis å¤±è´¥ï¼š%v", err)
		return results
	}

	// è®°å½•æ´»è·ƒè¿æ¥æ•°
	if prometheusMetrics != nil {
		prometheusMetrics.UpdateActiveConnections("redis", 1) // Redis å•è¿æ¥
	}

	// è¿è¡Œä¸åŒçš„æµ‹è¯•åœºæ™¯
	testCases := []struct {
		name     string
		testFunc func(*redis.Client, TestConfig, *PrometheusMetrics) TestResult
	}{
		{"é«˜ååé‡æµ‹è¯•", runRedisHighThroughputTest},
		{"å¹¶å‘å·¥ä½œçº¿ç¨‹æµ‹è¯•", runRedisConcurrentWorkersTest},
		{"å¤§æ‰¹æ¬¡æµ‹è¯•", runRedisLargeBatchTest},
		{"å†…å­˜å‹åŠ›æµ‹è¯•", runRedisMemoryPressureTest},
		{"é•¿æ—¶é—´è¿è¡Œæµ‹è¯•", runRedisLongDurationTest},
	}

	for _, tc := range testCases {
		// æ¯ä¸ªæµ‹è¯•å‰æ¸…ç† Redis æ•°æ®
		log.Printf("  ğŸ§¹ åœ¨è¿è¡Œ %s å‰æ¸…ç† Redis æ•°æ®...", tc.name)
		if err := rdb.FlushDB(ctx).Err(); err != nil {
			log.Printf("âŒ Failed to flush Redis DB before %s: %v", tc.name, err)
		}

		log.Printf("  ğŸ”„ åœ¨ Redis ä¸Šè¿è¡Œ %s...", tc.name)
		result := tc.testFunc(rdb, config, prometheusMetrics)
		result.TestName = tc.name
		result.Database = "redis"
		results = append(results, result)

		// å®æ—¶è®°å½•æµ‹è¯•ç»“æœåˆ° Prometheus
		if prometheusMetrics != nil {
			prometheusMetrics.RecordTestResult(result)
		}

		// æµ‹è¯•é—´éš”ï¼Œè®©ç³»ç»Ÿæ¢å¤
		time.Sleep(5 * time.Second)
	}

	return results
}

// runRedisHighThroughputTest Redis é«˜ååé‡æµ‹è¯•
func runRedisHighThroughputTest(rdb *redis.Client, config TestConfig, prometheusMetrics *PrometheusMetrics) TestResult {
	ctx := context.Background()

	executor := batchsql.NewRedisThrottledBatchExecutor(rdb)
	if prometheusMetrics != nil {
		metricsReporter := NewPrometheusMetricsReporter(prometheusMetrics, "redis", "é«˜ååé‡æµ‹è¯•")
		executor.WithMetricsReporter(metricsReporter)
	}
	batchSQL := batchsql.NewBatchSQL(ctx, config.BufferSize, config.BatchSize, config.FlushInterval, executor)

	// Redis ä½¿ç”¨ç®€å•çš„ key-value schema
	schema := batchsql.NewSchema("redis_test", batchsql.ConflictIgnore,
		"cmd", "key", "value", "ex_flag", "ttl")

	startTime := time.Now()
	var recordCount int64
	var errors []string

	// è®°å½•åˆå§‹å†…å­˜
	var m1 runtime.MemStats
	runtime.GC()
	runtime.ReadMemStats(&m1)

	// é«˜ååé‡æµ‹è¯•
	testCtx, cancel := context.WithTimeout(ctx, config.TestDuration)
	defer cancel()

	maxRecords := int64(config.ConcurrentWorkers * config.RecordsPerWorker)

	for i := int64(0); i < maxRecords; i++ {
		select {
		case <-testCtx.Done():
			goto TestComplete
		default:
			request := batchsql.NewRequest(schema).
				SetString("cmd", "SET").
				SetString("key", fmt.Sprintf("test:user:%d", i)).
				SetString("value", fmt.Sprintf(`{"id":%d,"name":"User_%d","email":"user_%d@example.com","active":%t}`, i, i, i, i%2 == 0)).
				SetString("ex_flag", "EX").
				SetInt64("ttl", 3600000) // 1å°æ—¶ TTL (æ¯«ç§’)

			batchStartTime := time.Now()

			if err := batchSQL.Submit(testCtx, request); err != nil {
				errors = append(errors, err.Error())
				if len(errors) > 100 {
					break
				}
			} else {
				recordCount++

				// è®°å½•æ‰¹å¤„ç†æ—¶é—´å’Œå“åº”æ—¶é—´
				if prometheusMetrics != nil {
					batchDuration := time.Since(batchStartTime)
					prometheusMetrics.RecordBatchProcessTime("redis", config.BatchSize, batchDuration)
					prometheusMetrics.RecordResponseTime("redis", "set", batchDuration)
				}
			}

			// å®šæœŸæ›´æ–°å®æ—¶æŒ‡æ ‡
			if i%1000 == 0 {
				runtime.GC()

				// æ›´æ–°å®æ—¶ RPS å’Œå†…å­˜ä½¿ç”¨
				if prometheusMetrics != nil {
					elapsed := time.Since(startTime).Seconds()
					if elapsed > 0 {
						currentRPS := float64(recordCount) / elapsed
						prometheusMetrics.UpdateCurrentRPS("redis", "é«˜ååé‡æµ‹è¯•", currentRPS)
					}

					// æ›´æ–°å†…å­˜ä½¿ç”¨
					var m runtime.MemStats
					runtime.ReadMemStats(&m)
					prometheusMetrics.UpdateMemoryUsage("redis", "é«˜ååé‡æµ‹è¯•",
						float64(m.Alloc)/1024/1024,
						float64(m.TotalAlloc)/1024/1024,
						float64(m.Sys)/1024/1024)
				}
			}
		}
	}

TestComplete:
	duration := time.Since(startTime)

	log.Printf("ğŸ” æµ‹è¯•å®Œæˆï¼Œæäº¤äº† %d æ¡è®°å½•ï¼Œè€—æ—¶ %v", recordCount, duration)
	log.Printf("ğŸ” ç­‰å¾…Rediså¤„ç†å®Œæˆ...")

	// ç­‰å¾…å¤„ç†å®Œæˆ
	time.Sleep(5 * time.Second)

	// è®°å½•æœ€ç»ˆå†…å­˜
	var m2 runtime.MemStats
	runtime.GC()
	runtime.ReadMemStats(&m2)

	log.Printf("ğŸ” å¼€å§‹ç»Ÿè®¡Redisä¸­çš„å®é™…è®°å½•æ•°...")

	// æŸ¥è¯¢ Redis ä¸­çš„å®é™…è®°å½•æ•°
	actualRecords, countErr := getRedisRecordCount(rdb, ctx)
	if countErr != nil {
		log.Printf("âŒ ç»Ÿè®¡å®é™…è®°å½•æ•°å¤±è´¥ï¼š%v", countErr)
		errors = append(errors, fmt.Sprintf("ç»Ÿè®¡å®é™…è®°å½•æ•°å¤±è´¥ï¼š%v", countErr))
		actualRecords = -1
	} else {
		log.Printf("ğŸ” ç»Ÿè®¡å®Œæˆ - æäº¤: %d, å®é™…: %d", recordCount, actualRecords)
	}

	// è®¡ç®—æ•°æ®å®Œæ•´æ€§
	dataIntegrityRate, integrityStatus, rpsValid, rpsNote := calculateDataIntegrity(recordCount, actualRecords)

	// åªæœ‰åœ¨æ•°æ®å®Œæ•´æ€§100%æ—¶æ‰è®¡ç®—æœ‰æ•ˆçš„RPS
	rps := 0.0
	if rpsValid && duration.Seconds() > 0 {
		rps = float64(recordCount) / duration.Seconds()
	}

	return TestResult{
		Duration:            duration,
		TotalRecords:        recordCount,
		ActualRecords:       actualRecords,
		DataIntegrityRate:   dataIntegrityRate,
		DataIntegrityStatus: integrityStatus,
		RecordsPerSecond:    rps,
		RPSValid:            rpsValid,
		RPSNote:             rpsNote,
		ConcurrentWorkers:   1,
		TestParameters: TestParams{
			BatchSize:       config.BatchSize,
			BufferSize:      config.BufferSize,
			FlushInterval:   config.FlushInterval,
			ExpectedRecords: int64(config.ConcurrentWorkers * config.RecordsPerWorker),
			TestDuration:    config.TestDuration,
		},
		MemoryUsage: MemoryStats{
			AllocMB:      calculateMemoryDiffMB(m2.Alloc, m1.Alloc),
			TotalAllocMB: calculateMemoryDiffMB(m2.TotalAlloc, m1.TotalAlloc),
			SysMB:        calculateMemoryDiffMB(m2.Sys, m1.Sys),
			NumGC:        m2.NumGC - m1.NumGC,
		},
		Errors:  errors,
		Success: len(errors) == 0 && rpsValid,
	}
}

// runRedisConcurrentWorkersTest Redis å¹¶å‘å·¥ä½œçº¿ç¨‹æµ‹è¯•
func runRedisConcurrentWorkersTest(rdb *redis.Client, config TestConfig, prometheusMetrics *PrometheusMetrics) TestResult {
	ctx := context.Background()

	batchSQL := batchsql.NewRedisBatchSQL(ctx, rdb, batchsql.PipelineConfig{
		BufferSize:    config.BufferSize,
		FlushSize:     config.BatchSize,
		FlushInterval: config.FlushInterval,
	})

	schema := batchsql.NewSchema("redis_test", batchsql.ConflictIgnore,
		"cmd", "key", "value", "ex_flag", "ttl")

	startTime := time.Now()
	var totalRecords int64
	var mu sync.Mutex
	var errors []string

	// è®°å½•åˆå§‹å†…å­˜
	var m1 runtime.MemStats
	runtime.GC()
	runtime.ReadMemStats(&m1)

	// å¹¶å‘å·¥ä½œè€…æµ‹è¯•
	var wg sync.WaitGroup
	batchSize := 100

	for workerID := 0; workerID < config.ConcurrentWorkers; workerID++ {
		wg.Add(1)
		go func(id int) {
			defer wg.Done()

			workerRecords := 0
			baseID := int64(id * config.RecordsPerWorker)

			for batch := 0; batch < config.RecordsPerWorker; batch += batchSize {
				endIdx := batch + batchSize
				if endIdx > config.RecordsPerWorker {
					endIdx = config.RecordsPerWorker
				}

				for i := batch; i < endIdx; i++ {
					request := batchsql.NewRequest(schema).
						SetString("cmd", "SET").
						SetString("key", fmt.Sprintf("test:worker:%d:user:%d", id, baseID+int64(i))).
						SetString("value", fmt.Sprintf(`{"worker_id":%d,"user_id":%d,"name":"W%d_U%d","active":%t}`, id, baseID+int64(i), id, i, (id+i)%2 == 0)).
						SetString("ex_flag", "EX").
						SetInt64("ttl", 3600000) // 1å°æ—¶ TTL

					if err := batchSQL.Submit(ctx, request); err != nil {
						mu.Lock()
						errors = append(errors, fmt.Sprintf("Worker %d: %v", id, err))
						mu.Unlock()
					} else {
						workerRecords++
					}
				}

				runtime.GC()
				time.Sleep(10 * time.Millisecond)
			}

			mu.Lock()
			totalRecords += int64(workerRecords)
			mu.Unlock()
		}(workerID)
	}

	wg.Wait()
	duration := time.Since(startTime)

	// ç­‰å¾…å¤„ç†å®Œæˆ
	time.Sleep(5 * time.Second)

	// è®°å½•æœ€ç»ˆå†…å­˜
	var m2 runtime.MemStats
	runtime.GC()
	runtime.ReadMemStats(&m2)

	// æŸ¥è¯¢ Redis ä¸­çš„å®é™…è®°å½•æ•°
	actualRecords, countErr := getRedisRecordCount(rdb, ctx)
	if countErr != nil {
		mu.Lock()
		errors = append(errors, fmt.Sprintf("ç»Ÿè®¡å®é™…è®°å½•æ•°å¤±è´¥ï¼š%v", countErr))
		mu.Unlock()
		actualRecords = -1
	}

	// è®¡ç®—æ•°æ®å®Œæ•´æ€§
	dataIntegrityRate, integrityStatus, rpsValid, rpsNote := calculateDataIntegrity(totalRecords, actualRecords)

	// åªæœ‰åœ¨æ•°æ®å®Œæ•´æ€§100%æ—¶æ‰è®¡ç®—æœ‰æ•ˆçš„RPS
	rps := 0.0
	if rpsValid && duration.Seconds() > 0 {
		rps = float64(totalRecords) / duration.Seconds()
	}

	return TestResult{
		Duration:            duration,
		TotalRecords:        totalRecords,
		ActualRecords:       actualRecords,
		DataIntegrityRate:   dataIntegrityRate,
		DataIntegrityStatus: integrityStatus,
		RecordsPerSecond:    rps,
		RPSValid:            rpsValid,
		RPSNote:             rpsNote,
		ConcurrentWorkers:   config.ConcurrentWorkers,
		TestParameters: TestParams{
			BatchSize:       config.BatchSize,
			BufferSize:      config.BufferSize,
			FlushInterval:   config.FlushInterval,
			ExpectedRecords: int64(config.ConcurrentWorkers * config.RecordsPerWorker),
			TestDuration:    config.TestDuration,
		},
		MemoryUsage: MemoryStats{
			AllocMB:      calculateMemoryDiffMB(m2.Alloc, m1.Alloc),
			TotalAllocMB: calculateMemoryDiffMB(m2.TotalAlloc, m1.TotalAlloc),
			SysMB:        calculateMemoryDiffMB(m2.Sys, m1.Sys),
			NumGC:        m2.NumGC - m1.NumGC,
		},
		Errors:  errors,
		Success: len(errors) == 0 && rpsValid,
	}
}

// runRedisLargeBatchTest Redis å¤§æ‰¹æ¬¡æµ‹è¯•
func runRedisLargeBatchTest(rdb *redis.Client, config TestConfig, prometheusMetrics *PrometheusMetrics) TestResult {
	largeConfig := config
	largeConfig.BatchSize = 5000
	largeConfig.BufferSize = 50000

	result := runRedisHighThroughputTest(rdb, largeConfig, prometheusMetrics)
	result.TestName = "Large Batch Test"
	return result
}

// runRedisMemoryPressureTest Redis å†…å­˜å‹åŠ›æµ‹è¯•
func runRedisMemoryPressureTest(rdb *redis.Client, config TestConfig, prometheusMetrics *PrometheusMetrics) TestResult {
	memConfig := config
	memConfig.BatchSize = 100
	memConfig.BufferSize = 1000
	memConfig.RecordsPerWorker = 50000

	result := runRedisConcurrentWorkersTest(rdb, memConfig, prometheusMetrics)
	result.TestName = "Memory Pressure Test"
	return result
}

// runRedisLongDurationTest Redis é•¿æ—¶é—´è¿è¡Œæµ‹è¯•
func runRedisLongDurationTest(rdb *redis.Client, config TestConfig, prometheusMetrics *PrometheusMetrics) TestResult {
	longConfig := config
	longConfig.TestDuration = 10 * time.Minute

	result := runRedisHighThroughputTest(rdb, longConfig, prometheusMetrics)
	result.TestName = "Long Duration Test"
	return result
}

// getRedisRecordCount è·å– Redis ä¸­çš„è®°å½•æ•°é‡
func getRedisRecordCount(rdb *redis.Client, ctx context.Context) (int64, error) {
	log.Printf("ğŸ” å¼€å§‹ç»Ÿè®¡Redisè®°å½•æ•°...")

	// ä½¿ç”¨ DBSIZE å‘½ä»¤è·å–å½“å‰æ•°æ®åº“ä¸­çš„ key æ•°é‡
	count, err := rdb.DBSize(ctx).Result()
	if err != nil {
		log.Printf("âŒ DBSIZEå‘½ä»¤æ‰§è¡Œå¤±è´¥: %v", err)
		return 0, err
	}

	log.Printf("ğŸ” DBSIZEè¿”å›ç»“æœ: %d", count)

	// é¢å¤–éªŒè¯ï¼šä½¿ç”¨KEYSå‘½ä»¤é‡‡æ ·æ£€æŸ¥ï¼ˆä»…ç”¨äºè°ƒè¯•ï¼Œç”Ÿäº§ç¯å¢ƒä¸æ¨èï¼‰
	keys, err := rdb.Keys(ctx, "test:*").Result()
	if err != nil {
		log.Printf("âš ï¸ KEYSå‘½ä»¤æ‰§è¡Œå¤±è´¥: %v", err)
	} else {
		log.Printf("ğŸ” KEYS test:* è¿”å›æ•°é‡: %d", len(keys))
		if len(keys) > 0 && len(keys) <= 5 {
			log.Printf("ğŸ” å‰å‡ ä¸ªkeyç¤ºä¾‹: %v", keys)
		}
	}

	return count, nil
}
