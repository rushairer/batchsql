package main

import (
	"context"
	"database/sql"
	"fmt"
	"log"
	"runtime"
	"sync"
	"time"

	"github.com/rushairer/batchsql"
	"github.com/rushairer/batchsql/drivers"
)

func runDatabaseTests(dbType, dsn string, config TestConfig) []TestResult {
	var results []TestResult

	// è¿æ¥æ•°æ®åº“
	db, err := sql.Open(dbType, dsn)
	if err != nil {
		log.Printf("âŒ è¿æ¥ %s å¤±è´¥ï¼š%v", dbType, err)
		return results
	}
	defer db.Close()

	// è®¾ç½®è¿æ¥æ± 
	db.SetMaxOpenConns(100)
	db.SetMaxIdleConns(50)
	db.SetConnMaxLifetime(time.Hour)

	// æµ‹è¯•è¿æ¥
	if err := db.Ping(); err != nil {
		log.Printf("âŒ Ping %s å¤±è´¥ï¼š%v", dbType, err)
		return results
	}

	// åˆ›å»ºæµ‹è¯•è¡¨
	if err := createTestTables(db, dbType); err != nil {
		log.Printf("âŒ ä¸º %s åˆ›å»ºæµ‹è¯•è¡¨å¤±è´¥ï¼š%v", dbType, err)
		return results
	}

	// è¿è¡Œä¸åŒçš„æµ‹è¯•åœºæ™¯
	testCases := []struct {
		name     string
		testFunc func(*sql.DB, string, TestConfig) TestResult
	}{
		{"é«˜ååé‡æµ‹è¯•", runHighThroughputTest},
		{"å¹¶å‘å·¥ä½œçº¿ç¨‹æµ‹è¯•", runConcurrentWorkersTest},
		{"å¤§æ‰¹æ¬¡æµ‹è¯•", runLargeBatchTest},
		{"å†…å­˜å‹åŠ›æµ‹è¯•", runMemoryPressureTest},
		{"é•¿æ—¶é—´è¿è¡Œæµ‹è¯•", runLongDurationTest},
	}

	for _, tc := range testCases {
		// æ¯ä¸ªæµ‹è¯•å‰æ¸…ç†è¡¨æ•°æ®ï¼Œç¡®ä¿æµ‹è¯•ç‹¬ç«‹æ€§
		log.Printf("  ğŸ§¹ åœ¨è¿è¡Œ %s å‰æ¸…ç†è¡¨æ•°æ®...", tc.name)
		if err := clearTestTable(db, dbType); err != nil {
			log.Printf("âŒ Failed to clear table before %s: %v", tc.name, err)
			// ç»§ç»­æ‰§è¡Œæµ‹è¯•ï¼Œä½†è®°å½•é”™è¯¯
		}

		log.Printf("  ğŸ”„ åœ¨ %s ä¸Šè¿è¡Œ %s...", dbType, tc.name)
		result := tc.testFunc(db, dbType, config)
		result.TestName = tc.name
		result.Database = dbType
		results = append(results, result)

		// æµ‹è¯•é—´éš”ï¼Œè®©ç³»ç»Ÿæ¢å¤
		time.Sleep(5 * time.Second)
	}

	return results
}

func createTestTables(db *sql.DB, dbType string) error {
	var createSQL string

	switch dbType {
	case "mysql":
		createSQL = `
		DROP TABLE IF EXISTS integration_test;
		CREATE TABLE integration_test (
			id BIGINT PRIMARY KEY,
			name VARCHAR(255) NOT NULL,
			email VARCHAR(255) NOT NULL,
			data TEXT,
			value DECIMAL(10,2),
			is_active BOOLEAN DEFAULT TRUE,
			created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
			INDEX idx_name (name),
			INDEX idx_email (email)
		) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4;
		`
	case "postgres":
		createSQL = `
		DROP TABLE IF EXISTS integration_test;
		CREATE TABLE integration_test (
			id BIGINT PRIMARY KEY,
			name VARCHAR(255) NOT NULL,
			email VARCHAR(255) NOT NULL,
			data TEXT,
			value DECIMAL(10,2),
			is_active BOOLEAN DEFAULT TRUE,
			created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
		);
		
		CREATE INDEX IF NOT EXISTS idx_name ON integration_test(name);
		CREATE INDEX IF NOT EXISTS idx_email ON integration_test(email);
		`
	case "sqlite3":
		createSQL = `
		DROP TABLE IF EXISTS integration_test;
		CREATE TABLE integration_test (
			id INTEGER PRIMARY KEY,
			name TEXT NOT NULL,
			email TEXT NOT NULL,
			data TEXT,
			value REAL,
			is_active INTEGER DEFAULT 1,
			created_at DATETIME DEFAULT CURRENT_TIMESTAMP
		);
		
		CREATE INDEX IF NOT EXISTS idx_name ON integration_test(name);
		CREATE INDEX IF NOT EXISTS idx_email ON integration_test(email);
		`
	}

	_, err := db.Exec(createSQL)
	return err
}

// éªŒè¯æ•°æ®åº“ä¸­çš„å®é™…è®°å½•æ•°
func getSQLRecordCount(db *sql.DB) (int64, error) {
	var count int64
	err := db.QueryRow("SELECT COUNT(*) FROM integration_test").Scan(&count)
	return count, err
}

// æ¸…ç†æµ‹è¯•è¡¨æ•°æ® - ä½¿ç”¨é«˜æ€§èƒ½çš„æ¸…ç†æ–¹å¼
func clearTestTable(db *sql.DB, dbType string) error {
	switch dbType {
	case "mysql":
		// MySQL ä½¿ç”¨ TRUNCATEï¼Œæ€§èƒ½æœ€ä½³
		_, err := db.Exec("TRUNCATE TABLE integration_test")
		return err
	case "postgres":
		// PostgreSQL ä½¿ç”¨ TRUNCATEï¼Œæ”¯æŒçº§è”
		_, err := db.Exec("TRUNCATE TABLE integration_test RESTART IDENTITY")
		return err
	case "sqlite3":
		// SQLite ä½¿ç”¨é‡å»ºè¡¨æ–¹å¼ï¼Œé¿å…é”å®šé—®é¢˜
		return clearSQLiteTableByRecreate(db)
	default:
		// å…œåº•æ–¹æ¡ˆ
		_, err := db.Exec("DELETE FROM integration_test")
		return err
	}
}

// clearSQLiteTableByRecreate SQLiteä¸“ç”¨çš„é‡å»ºè¡¨æ¸…ç†æ–¹å¼
func clearSQLiteTableByRecreate(db *sql.DB) error {
	// 1. åˆ é™¤è¡¨
	if _, err := db.Exec("DROP TABLE IF EXISTS integration_test"); err != nil {
		return fmt.Errorf("failed to drop table: %v", err)
	}

	// 2. é‡æ–°åˆ›å»ºè¡¨
	createSQL := `
	CREATE TABLE integration_test (
		id INTEGER PRIMARY KEY,
		name TEXT NOT NULL,
		email TEXT NOT NULL,
		data TEXT,
		value REAL,
		is_active INTEGER DEFAULT 1,
		created_at DATETIME DEFAULT CURRENT_TIMESTAMP
	)`

	if _, err := db.Exec(createSQL); err != nil {
		return fmt.Errorf("failed to create table: %v", err)
	}

	// 3. é‡æ–°åˆ›å»ºç´¢å¼•
	indexes := []string{
		"CREATE INDEX IF NOT EXISTS idx_name ON integration_test(name)",
		"CREATE INDEX IF NOT EXISTS idx_email ON integration_test(email)",
	}

	for _, indexSQL := range indexes {
		if _, err := db.Exec(indexSQL); err != nil {
			return fmt.Errorf("failed to create index: %v", err)
		}
	}

	log.Printf("  âœ… å·²æˆåŠŸé‡å»º SQLite è¡¨")
	return nil
}

func runHighThroughputTest(db *sql.DB, dbType string, config TestConfig) TestResult {
	ctx := context.Background()

	var batchSQL *batchsql.BatchSQL
	switch dbType {
	case "mysql":
		batchSQL = batchsql.NewMySQLBatchSQL(ctx, db, batchsql.PipelineConfig{
			BufferSize:    config.BufferSize,
			FlushSize:     config.BatchSize,
			FlushInterval: config.FlushInterval,
		})
	case "postgres":
		batchSQL = batchsql.NewPostgreSQLBatchSQL(ctx, db, batchsql.PipelineConfig{
			BufferSize:    config.BufferSize,
			FlushSize:     config.BatchSize,
			FlushInterval: config.FlushInterval,
		})
	case "sqlite3":
		batchSQL = batchsql.NewSQLiteBatchSQL(ctx, db, batchsql.PipelineConfig{
			BufferSize:    config.BufferSize,
			FlushSize:     config.BatchSize,
			FlushInterval: config.FlushInterval,
		})
	}

	schema := batchsql.NewSchema("integration_test", drivers.ConflictIgnore,
		"id", "name", "email", "data", "value", "is_active", "created_at")

	startTime := time.Now()
	var recordCount int64
	var errors []string

	// è®°å½•åˆå§‹å†…å­˜
	var m1 runtime.MemStats
	runtime.GC()
	runtime.ReadMemStats(&m1)

	// é«˜ååé‡æµ‹è¯• - é™åˆ¶è®°å½•æ•°é‡é¿å…å†…å­˜æ³„æ¼
	testCtx, cancel := context.WithTimeout(ctx, config.TestDuration)
	defer cancel()

	maxRecords := int64(config.ConcurrentWorkers * config.RecordsPerWorker) // é™åˆ¶æœ€å¤§è®°å½•æ•°

	for i := int64(0); i < maxRecords; i++ {
		select {
		case <-testCtx.Done():
			goto TestComplete
		default:
			request := batchsql.NewRequest(schema).
				SetInt64("id", i).
				SetString("name", fmt.Sprintf("User_%d", i)).
				SetString("email", fmt.Sprintf("user_%d@example.com", i)).
				SetString("data", fmt.Sprintf("Data_%d", i)). // å‡å°‘å­—ç¬¦ä¸²é•¿åº¦
				SetFloat64("value", float64(i%10000)/100.0).
				SetBool("is_active", i%2 == 0).
				SetTime("created_at", time.Now().UTC()) // å†™å…¥ UTC

			if err := batchSQL.Submit(testCtx, request); err != nil {
				errors = append(errors, err.Error())
				if len(errors) > 100 { // é™åˆ¶é”™è¯¯æ•°é‡
					break
				}
			} else {
				recordCount++
			}

			// å®šæœŸå¼ºåˆ¶GCï¼Œé¿å…å†…å­˜ç§¯ç´¯
			if i%1000 == 0 {
				runtime.GC()
			}
		}
	}

TestComplete:
	duration := time.Since(startTime)

	// ç­‰å¾…å¤„ç†å®Œæˆ
	time.Sleep(5 * time.Second)

	// è®°å½•æœ€ç»ˆå†…å­˜
	var m2 runtime.MemStats
	runtime.GC()
	runtime.ReadMemStats(&m2)

	// æŸ¥è¯¢æ•°æ®åº“ä¸­çš„å®é™…è®°å½•æ•°
	actualRecords, countErr := getSQLRecordCount(db)
	if countErr != nil {
		errors = append(errors, fmt.Sprintf("ç»Ÿè®¡å®é™…è®°å½•æ•°å¤±è´¥ï¼š%v", countErr))
		actualRecords = -1 // æ ‡è®°ä¸ºæ— æ³•è·å–
	}

	// è®¡ç®—æ•°æ®å®Œæ•´æ€§
	dataIntegrityRate, integrityStatus, rpsValid, rpsNote := calculateDataIntegrity(recordCount, actualRecords)

	// åªæœ‰åœ¨æ•°æ®å®Œæ•´æ€§100%æ—¶æ‰è®¡ç®—æœ‰æ•ˆçš„RPS
	rps := 0.0
	if rpsValid && duration.Seconds() > 0 {
		rps = float64(recordCount) / duration.Seconds()
	}

	return TestResult{
		Duration:            duration,
		TotalRecords:        recordCount,
		ActualRecords:       actualRecords,
		DataIntegrityRate:   dataIntegrityRate,
		DataIntegrityStatus: integrityStatus,
		RecordsPerSecond:    rps,
		RPSValid:            rpsValid,
		RPSNote:             rpsNote,
		ConcurrentWorkers:   1,
		TestParameters: TestParams{
			BatchSize:       config.BatchSize,
			BufferSize:      config.BufferSize,
			FlushInterval:   config.FlushInterval,
			ExpectedRecords: int64(config.ConcurrentWorkers * config.RecordsPerWorker),
			TestDuration:    config.TestDuration,
		},
		MemoryUsage: MemoryStats{
			AllocMB:      calculateMemoryDiffMB(m2.Alloc, m1.Alloc),
			TotalAllocMB: calculateMemoryDiffMB(m2.TotalAlloc, m1.TotalAlloc),
			SysMB:        calculateMemoryDiffMB(m2.Sys, m1.Sys),
			NumGC:        m2.NumGC - m1.NumGC,
		},
		Errors:  errors,
		Success: len(errors) == 0 && rpsValid, // åªæœ‰æ•°æ®å®Œæ•´æ€§100%æ‰ç®—æˆåŠŸ
	}
}

func runConcurrentWorkersTest(db *sql.DB, dbType string, config TestConfig) TestResult {
	ctx := context.Background()

	var batchSQL *batchsql.BatchSQL
	switch dbType {
	case "mysql":
		batchSQL = batchsql.NewMySQLBatchSQL(ctx, db, batchsql.PipelineConfig{
			BufferSize:    config.BufferSize,
			FlushSize:     config.BatchSize,
			FlushInterval: config.FlushInterval,
		})
	case "postgres":
		batchSQL = batchsql.NewPostgreSQLBatchSQL(ctx, db, batchsql.PipelineConfig{
			BufferSize:    config.BufferSize,
			FlushSize:     config.BatchSize,
			FlushInterval: config.FlushInterval,
		})
	case "sqlite3":
		batchSQL = batchsql.NewSQLiteBatchSQL(ctx, db, batchsql.PipelineConfig{
			BufferSize:    config.BufferSize,
			FlushSize:     config.BatchSize,
			FlushInterval: config.FlushInterval,
		})
	}

	schema := batchsql.NewSchema("integration_test", drivers.ConflictIgnore,
		"id", "name", "email", "data", "value", "is_active", "created_at")

	startTime := time.Now()
	var totalRecords int64
	var mu sync.Mutex
	var errors []string

	// è®°å½•åˆå§‹å†…å­˜
	var m1 runtime.MemStats
	runtime.GC()
	runtime.ReadMemStats(&m1)

	// å¹¶å‘å·¥ä½œè€…æµ‹è¯• - æ‰¹æ¬¡å¤„ç†é¿å…å†…å­˜å³°å€¼
	var wg sync.WaitGroup
	batchSize := 100 // æ¯æ‰¹å¤„ç†100æ¡è®°å½•

	for workerID := 0; workerID < config.ConcurrentWorkers; workerID++ {
		wg.Add(1)
		go func(id int) {
			defer wg.Done()

			workerRecords := 0
			baseID := int64(id * config.RecordsPerWorker)

			// åˆ†æ‰¹å¤„ç†ï¼Œé¿å…å†…å­˜å³°å€¼
			for batch := 0; batch < config.RecordsPerWorker; batch += batchSize {
				endIdx := batch + batchSize
				if endIdx > config.RecordsPerWorker {
					endIdx = config.RecordsPerWorker
				}

				for i := batch; i < endIdx; i++ {
					request := batchsql.NewRequest(schema).
						SetInt64("id", baseID+int64(i)).
						SetString("name", fmt.Sprintf("W%d_U%d", id, i)).          // ç¼©çŸ­å­—ç¬¦ä¸²
						SetString("email", fmt.Sprintf("u%d_%d@test.com", id, i)). // ç¼©çŸ­å­—ç¬¦ä¸²
						SetString("data", fmt.Sprintf("D%d_%d", id, i)).           // å¤§å¹…ç¼©çŸ­æ•°æ®
						SetFloat64("value", float64((id*100+i)%1000)/10.0).
						SetBool("is_active", (id+i)%2 == 0).
						SetTime("created_at", time.Now().UTC()) // å†™å…¥ UTC

					if err := batchSQL.Submit(ctx, request); err != nil {
						mu.Lock()
						errors = append(errors, fmt.Sprintf("Worker %d: %v", id, err))
						mu.Unlock()
					} else {
						workerRecords++
					}
				}

				// æ¯æ‰¹å¤„ç†å®Œåå¼ºåˆ¶GC
				runtime.GC()

				// æ·»åŠ å°å»¶è¿Ÿï¼Œé¿å…è¿‡åº¦ç«äº‰
				time.Sleep(10 * time.Millisecond)
			}

			mu.Lock()
			totalRecords += int64(workerRecords)
			mu.Unlock()
		}(workerID)
	}

	wg.Wait()
	duration := time.Since(startTime)

	// ç­‰å¾…å¤„ç†å®Œæˆ
	time.Sleep(5 * time.Second)

	// è®°å½•æœ€ç»ˆå†…å­˜
	var m2 runtime.MemStats
	runtime.GC()
	runtime.ReadMemStats(&m2)

	// æŸ¥è¯¢æ•°æ®åº“ä¸­çš„å®é™…è®°å½•æ•°
	actualRecords, countErr := getSQLRecordCount(db)
	if countErr != nil {
		mu.Lock()
		errors = append(errors, fmt.Sprintf("ç»Ÿè®¡å®é™…è®°å½•æ•°å¤±è´¥ï¼š%v", countErr))
		mu.Unlock()
		actualRecords = -1 // æ ‡è®°ä¸ºæ— æ³•è·å–
	}

	// è®¡ç®—æ•°æ®å®Œæ•´æ€§
	dataIntegrityRate, integrityStatus, rpsValid, rpsNote := calculateDataIntegrity(totalRecords, actualRecords)

	// åªæœ‰åœ¨æ•°æ®å®Œæ•´æ€§100%æ—¶æ‰è®¡ç®—æœ‰æ•ˆçš„RPS
	rps := 0.0
	if rpsValid && duration.Seconds() > 0 {
		rps = float64(totalRecords) / duration.Seconds()
	}

	return TestResult{
		Duration:            duration,
		TotalRecords:        totalRecords,
		ActualRecords:       actualRecords,
		DataIntegrityRate:   dataIntegrityRate,
		DataIntegrityStatus: integrityStatus,
		RecordsPerSecond:    rps,
		RPSValid:            rpsValid,
		RPSNote:             rpsNote,
		ConcurrentWorkers:   config.ConcurrentWorkers,
		TestParameters: TestParams{
			BatchSize:       config.BatchSize,
			BufferSize:      config.BufferSize,
			FlushInterval:   config.FlushInterval,
			ExpectedRecords: int64(config.ConcurrentWorkers * config.RecordsPerWorker),
			TestDuration:    config.TestDuration,
		},
		MemoryUsage: MemoryStats{
			AllocMB:      calculateMemoryDiffMB(m2.Alloc, m1.Alloc),
			TotalAllocMB: calculateMemoryDiffMB(m2.TotalAlloc, m1.TotalAlloc),
			SysMB:        calculateMemoryDiffMB(m2.Sys, m1.Sys),
			NumGC:        m2.NumGC - m1.NumGC,
		},
		Errors:  errors,
		Success: len(errors) == 0 && rpsValid, // åªæœ‰æ•°æ®å®Œæ•´æ€§100%æ‰ç®—æˆåŠŸ
	}
}

func runLargeBatchTest(db *sql.DB, dbType string, config TestConfig) TestResult {
	// å¤§æ‰¹æ¬¡æµ‹è¯• - ä½¿ç”¨æ›´å¤§çš„æ‰¹æ¬¡å¤§å°
	largeConfig := config
	largeConfig.BatchSize = 5000
	largeConfig.BufferSize = 50000

	result := runHighThroughputTest(db, dbType, largeConfig)
	result.TestName = "Large Batch Test"
	return result
}

func runMemoryPressureTest(db *sql.DB, dbType string, config TestConfig) TestResult {
	// å†…å­˜å‹åŠ›æµ‹è¯• - ä½¿ç”¨å¤§æ•°æ®é‡å’Œå°æ‰¹æ¬¡
	memConfig := config
	memConfig.BatchSize = 100
	memConfig.BufferSize = 1000
	memConfig.RecordsPerWorker = 50000

	result := runConcurrentWorkersTest(db, dbType, memConfig)
	result.TestName = "Memory Pressure Test"
	return result
}

func runLongDurationTest(db *sql.DB, dbType string, config TestConfig) TestResult {
	// é•¿æ—¶é—´è¿è¡Œæµ‹è¯•
	longConfig := config
	longConfig.TestDuration = 10 * time.Minute

	result := runHighThroughputTest(db, dbType, longConfig)
	result.TestName = "Long Duration Test"
	return result
}
