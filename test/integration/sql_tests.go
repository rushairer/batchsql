package main

import (
	"context"
	"database/sql"
	"fmt"
	"log"
	"runtime"
	"sync"
	"time"

	"github.com/rushairer/batchsql"
	"github.com/rushairer/batchsql/drivers"
)

func runDatabaseTests(dbType, dsn string, config TestConfig) []TestResult {
	var results []TestResult

	// 连接数据库
	db, err := sql.Open(dbType, dsn)
	if err != nil {
		log.Printf("❌ 连接 %s 失败：%v", dbType, err)
		return results
	}
	defer db.Close()

	// 设置连接池
	db.SetMaxOpenConns(100)
	db.SetMaxIdleConns(50)
	db.SetConnMaxLifetime(time.Hour)

	// 测试连接
	if err := db.Ping(); err != nil {
		log.Printf("❌ Ping %s 失败：%v", dbType, err)
		return results
	}

	// 创建测试表
	if err := createTestTables(db, dbType); err != nil {
		log.Printf("❌ 为 %s 创建测试表失败：%v", dbType, err)
		return results
	}

	// 运行不同的测试场景
	testCases := []struct {
		name     string
		testFunc func(*sql.DB, string, TestConfig) TestResult
	}{
		{"高吞吐量测试", runHighThroughputTest},
		{"并发工作线程测试", runConcurrentWorkersTest},
		{"大批次测试", runLargeBatchTest},
		{"内存压力测试", runMemoryPressureTest},
		{"长时间运行测试", runLongDurationTest},
	}

	for _, tc := range testCases {
		// 每个测试前清理表数据，确保测试独立性
		log.Printf("  🧹 在运行 %s 前清理表数据...", tc.name)
		if err := clearTestTable(db, dbType); err != nil {
			log.Printf("❌ Failed to clear table before %s: %v", tc.name, err)
			// 继续执行测试，但记录错误
		}

		log.Printf("  🔄 在 %s 上运行 %s...", dbType, tc.name)
		result := tc.testFunc(db, dbType, config)
		result.TestName = tc.name
		result.Database = dbType
		results = append(results, result)

		// 测试间隔，让系统恢复
		time.Sleep(5 * time.Second)
	}

	return results
}

func createTestTables(db *sql.DB, dbType string) error {
	var createSQL string

	switch dbType {
	case "mysql":
		createSQL = `
		DROP TABLE IF EXISTS integration_test;
		CREATE TABLE integration_test (
			id BIGINT PRIMARY KEY,
			name VARCHAR(255) NOT NULL,
			email VARCHAR(255) NOT NULL,
			data TEXT,
			value DECIMAL(10,2),
			is_active BOOLEAN DEFAULT TRUE,
			created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
			INDEX idx_name (name),
			INDEX idx_email (email)
		) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4;
		`
	case "postgres":
		createSQL = `
		DROP TABLE IF EXISTS integration_test;
		CREATE TABLE integration_test (
			id BIGINT PRIMARY KEY,
			name VARCHAR(255) NOT NULL,
			email VARCHAR(255) NOT NULL,
			data TEXT,
			value DECIMAL(10,2),
			is_active BOOLEAN DEFAULT TRUE,
			created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
		);
		
		CREATE INDEX IF NOT EXISTS idx_name ON integration_test(name);
		CREATE INDEX IF NOT EXISTS idx_email ON integration_test(email);
		`
	case "sqlite3":
		createSQL = `
		DROP TABLE IF EXISTS integration_test;
		CREATE TABLE integration_test (
			id INTEGER PRIMARY KEY,
			name TEXT NOT NULL,
			email TEXT NOT NULL,
			data TEXT,
			value REAL,
			is_active INTEGER DEFAULT 1,
			created_at DATETIME DEFAULT CURRENT_TIMESTAMP
		);
		
		CREATE INDEX IF NOT EXISTS idx_name ON integration_test(name);
		CREATE INDEX IF NOT EXISTS idx_email ON integration_test(email);
		`
	}

	_, err := db.Exec(createSQL)
	return err
}

// 验证数据库中的实际记录数
func getSQLRecordCount(db *sql.DB) (int64, error) {
	var count int64
	err := db.QueryRow("SELECT COUNT(*) FROM integration_test").Scan(&count)
	return count, err
}

// 清理测试表数据 - 使用高性能的清理方式
func clearTestTable(db *sql.DB, dbType string) error {
	switch dbType {
	case "mysql":
		// MySQL 使用 TRUNCATE，性能最佳
		_, err := db.Exec("TRUNCATE TABLE integration_test")
		return err
	case "postgres":
		// PostgreSQL 使用 TRUNCATE，支持级联
		_, err := db.Exec("TRUNCATE TABLE integration_test RESTART IDENTITY")
		return err
	case "sqlite3":
		// SQLite 使用重建表方式，避免锁定问题
		return clearSQLiteTableByRecreate(db)
	default:
		// 兜底方案
		_, err := db.Exec("DELETE FROM integration_test")
		return err
	}
}

// clearSQLiteTableByRecreate SQLite专用的重建表清理方式
func clearSQLiteTableByRecreate(db *sql.DB) error {
	// 1. 删除表
	if _, err := db.Exec("DROP TABLE IF EXISTS integration_test"); err != nil {
		return fmt.Errorf("failed to drop table: %v", err)
	}

	// 2. 重新创建表
	createSQL := `
	CREATE TABLE integration_test (
		id INTEGER PRIMARY KEY,
		name TEXT NOT NULL,
		email TEXT NOT NULL,
		data TEXT,
		value REAL,
		is_active INTEGER DEFAULT 1,
		created_at DATETIME DEFAULT CURRENT_TIMESTAMP
	)`

	if _, err := db.Exec(createSQL); err != nil {
		return fmt.Errorf("failed to create table: %v", err)
	}

	// 3. 重新创建索引
	indexes := []string{
		"CREATE INDEX IF NOT EXISTS idx_name ON integration_test(name)",
		"CREATE INDEX IF NOT EXISTS idx_email ON integration_test(email)",
	}

	for _, indexSQL := range indexes {
		if _, err := db.Exec(indexSQL); err != nil {
			return fmt.Errorf("failed to create index: %v", err)
		}
	}

	log.Printf("  ✅ 已成功重建 SQLite 表")
	return nil
}

func runHighThroughputTest(db *sql.DB, dbType string, config TestConfig) TestResult {
	ctx := context.Background()

	var batchSQL *batchsql.BatchSQL
	switch dbType {
	case "mysql":
		batchSQL = batchsql.NewMySQLBatchSQL(ctx, db, batchsql.PipelineConfig{
			BufferSize:    config.BufferSize,
			FlushSize:     config.BatchSize,
			FlushInterval: config.FlushInterval,
		})
	case "postgres":
		batchSQL = batchsql.NewPostgreSQLBatchSQL(ctx, db, batchsql.PipelineConfig{
			BufferSize:    config.BufferSize,
			FlushSize:     config.BatchSize,
			FlushInterval: config.FlushInterval,
		})
	case "sqlite3":
		batchSQL = batchsql.NewSQLiteBatchSQL(ctx, db, batchsql.PipelineConfig{
			BufferSize:    config.BufferSize,
			FlushSize:     config.BatchSize,
			FlushInterval: config.FlushInterval,
		})
	}

	schema := batchsql.NewSchema("integration_test", drivers.ConflictIgnore,
		"id", "name", "email", "data", "value", "is_active", "created_at")

	startTime := time.Now()
	var recordCount int64
	var errors []string

	// 记录初始内存
	var m1 runtime.MemStats
	runtime.GC()
	runtime.ReadMemStats(&m1)

	// 高吞吐量测试 - 限制记录数量避免内存泄漏
	testCtx, cancel := context.WithTimeout(ctx, config.TestDuration)
	defer cancel()

	maxRecords := int64(config.ConcurrentWorkers * config.RecordsPerWorker) // 限制最大记录数

	for i := int64(0); i < maxRecords; i++ {
		select {
		case <-testCtx.Done():
			goto TestComplete
		default:
			request := batchsql.NewRequest(schema).
				SetInt64("id", i).
				SetString("name", fmt.Sprintf("User_%d", i)).
				SetString("email", fmt.Sprintf("user_%d@example.com", i)).
				SetString("data", fmt.Sprintf("Data_%d", i)). // 减少字符串长度
				SetFloat64("value", float64(i%10000)/100.0).
				SetBool("is_active", i%2 == 0).
				SetTime("created_at", time.Now().UTC()) // 写入 UTC

			if err := batchSQL.Submit(testCtx, request); err != nil {
				errors = append(errors, err.Error())
				if len(errors) > 100 { // 限制错误数量
					break
				}
			} else {
				recordCount++
			}

			// 定期强制GC，避免内存积累
			if i%1000 == 0 {
				runtime.GC()
			}
		}
	}

TestComplete:
	duration := time.Since(startTime)

	// 等待处理完成
	time.Sleep(5 * time.Second)

	// 记录最终内存
	var m2 runtime.MemStats
	runtime.GC()
	runtime.ReadMemStats(&m2)

	// 查询数据库中的实际记录数
	actualRecords, countErr := getSQLRecordCount(db)
	if countErr != nil {
		errors = append(errors, fmt.Sprintf("统计实际记录数失败：%v", countErr))
		actualRecords = -1 // 标记为无法获取
	}

	// 计算数据完整性
	dataIntegrityRate, integrityStatus, rpsValid, rpsNote := calculateDataIntegrity(recordCount, actualRecords)

	// 只有在数据完整性100%时才计算有效的RPS
	rps := 0.0
	if rpsValid && duration.Seconds() > 0 {
		rps = float64(recordCount) / duration.Seconds()
	}

	return TestResult{
		Duration:            duration,
		TotalRecords:        recordCount,
		ActualRecords:       actualRecords,
		DataIntegrityRate:   dataIntegrityRate,
		DataIntegrityStatus: integrityStatus,
		RecordsPerSecond:    rps,
		RPSValid:            rpsValid,
		RPSNote:             rpsNote,
		ConcurrentWorkers:   1,
		TestParameters: TestParams{
			BatchSize:       config.BatchSize,
			BufferSize:      config.BufferSize,
			FlushInterval:   config.FlushInterval,
			ExpectedRecords: int64(config.ConcurrentWorkers * config.RecordsPerWorker),
			TestDuration:    config.TestDuration,
		},
		MemoryUsage: MemoryStats{
			AllocMB:      calculateMemoryDiffMB(m2.Alloc, m1.Alloc),
			TotalAllocMB: calculateMemoryDiffMB(m2.TotalAlloc, m1.TotalAlloc),
			SysMB:        calculateMemoryDiffMB(m2.Sys, m1.Sys),
			NumGC:        m2.NumGC - m1.NumGC,
		},
		Errors:  errors,
		Success: len(errors) == 0 && rpsValid, // 只有数据完整性100%才算成功
	}
}

func runConcurrentWorkersTest(db *sql.DB, dbType string, config TestConfig) TestResult {
	ctx := context.Background()

	var batchSQL *batchsql.BatchSQL
	switch dbType {
	case "mysql":
		batchSQL = batchsql.NewMySQLBatchSQL(ctx, db, batchsql.PipelineConfig{
			BufferSize:    config.BufferSize,
			FlushSize:     config.BatchSize,
			FlushInterval: config.FlushInterval,
		})
	case "postgres":
		batchSQL = batchsql.NewPostgreSQLBatchSQL(ctx, db, batchsql.PipelineConfig{
			BufferSize:    config.BufferSize,
			FlushSize:     config.BatchSize,
			FlushInterval: config.FlushInterval,
		})
	case "sqlite3":
		batchSQL = batchsql.NewSQLiteBatchSQL(ctx, db, batchsql.PipelineConfig{
			BufferSize:    config.BufferSize,
			FlushSize:     config.BatchSize,
			FlushInterval: config.FlushInterval,
		})
	}

	schema := batchsql.NewSchema("integration_test", drivers.ConflictIgnore,
		"id", "name", "email", "data", "value", "is_active", "created_at")

	startTime := time.Now()
	var totalRecords int64
	var mu sync.Mutex
	var errors []string

	// 记录初始内存
	var m1 runtime.MemStats
	runtime.GC()
	runtime.ReadMemStats(&m1)

	// 并发工作者测试 - 批次处理避免内存峰值
	var wg sync.WaitGroup
	batchSize := 100 // 每批处理100条记录

	for workerID := 0; workerID < config.ConcurrentWorkers; workerID++ {
		wg.Add(1)
		go func(id int) {
			defer wg.Done()

			workerRecords := 0
			baseID := int64(id * config.RecordsPerWorker)

			// 分批处理，避免内存峰值
			for batch := 0; batch < config.RecordsPerWorker; batch += batchSize {
				endIdx := batch + batchSize
				if endIdx > config.RecordsPerWorker {
					endIdx = config.RecordsPerWorker
				}

				for i := batch; i < endIdx; i++ {
					request := batchsql.NewRequest(schema).
						SetInt64("id", baseID+int64(i)).
						SetString("name", fmt.Sprintf("W%d_U%d", id, i)).          // 缩短字符串
						SetString("email", fmt.Sprintf("u%d_%d@test.com", id, i)). // 缩短字符串
						SetString("data", fmt.Sprintf("D%d_%d", id, i)).           // 大幅缩短数据
						SetFloat64("value", float64((id*100+i)%1000)/10.0).
						SetBool("is_active", (id+i)%2 == 0).
						SetTime("created_at", time.Now().UTC()) // 写入 UTC

					if err := batchSQL.Submit(ctx, request); err != nil {
						mu.Lock()
						errors = append(errors, fmt.Sprintf("Worker %d: %v", id, err))
						mu.Unlock()
					} else {
						workerRecords++
					}
				}

				// 每批处理完后强制GC
				runtime.GC()

				// 添加小延迟，避免过度竞争
				time.Sleep(10 * time.Millisecond)
			}

			mu.Lock()
			totalRecords += int64(workerRecords)
			mu.Unlock()
		}(workerID)
	}

	wg.Wait()
	duration := time.Since(startTime)

	// 等待处理完成
	time.Sleep(5 * time.Second)

	// 记录最终内存
	var m2 runtime.MemStats
	runtime.GC()
	runtime.ReadMemStats(&m2)

	// 查询数据库中的实际记录数
	actualRecords, countErr := getSQLRecordCount(db)
	if countErr != nil {
		mu.Lock()
		errors = append(errors, fmt.Sprintf("统计实际记录数失败：%v", countErr))
		mu.Unlock()
		actualRecords = -1 // 标记为无法获取
	}

	// 计算数据完整性
	dataIntegrityRate, integrityStatus, rpsValid, rpsNote := calculateDataIntegrity(totalRecords, actualRecords)

	// 只有在数据完整性100%时才计算有效的RPS
	rps := 0.0
	if rpsValid && duration.Seconds() > 0 {
		rps = float64(totalRecords) / duration.Seconds()
	}

	return TestResult{
		Duration:            duration,
		TotalRecords:        totalRecords,
		ActualRecords:       actualRecords,
		DataIntegrityRate:   dataIntegrityRate,
		DataIntegrityStatus: integrityStatus,
		RecordsPerSecond:    rps,
		RPSValid:            rpsValid,
		RPSNote:             rpsNote,
		ConcurrentWorkers:   config.ConcurrentWorkers,
		TestParameters: TestParams{
			BatchSize:       config.BatchSize,
			BufferSize:      config.BufferSize,
			FlushInterval:   config.FlushInterval,
			ExpectedRecords: int64(config.ConcurrentWorkers * config.RecordsPerWorker),
			TestDuration:    config.TestDuration,
		},
		MemoryUsage: MemoryStats{
			AllocMB:      calculateMemoryDiffMB(m2.Alloc, m1.Alloc),
			TotalAllocMB: calculateMemoryDiffMB(m2.TotalAlloc, m1.TotalAlloc),
			SysMB:        calculateMemoryDiffMB(m2.Sys, m1.Sys),
			NumGC:        m2.NumGC - m1.NumGC,
		},
		Errors:  errors,
		Success: len(errors) == 0 && rpsValid, // 只有数据完整性100%才算成功
	}
}

func runLargeBatchTest(db *sql.DB, dbType string, config TestConfig) TestResult {
	// 大批次测试 - 使用更大的批次大小
	largeConfig := config
	largeConfig.BatchSize = 5000
	largeConfig.BufferSize = 50000

	result := runHighThroughputTest(db, dbType, largeConfig)
	result.TestName = "Large Batch Test"
	return result
}

func runMemoryPressureTest(db *sql.DB, dbType string, config TestConfig) TestResult {
	// 内存压力测试 - 使用大数据量和小批次
	memConfig := config
	memConfig.BatchSize = 100
	memConfig.BufferSize = 1000
	memConfig.RecordsPerWorker = 50000

	result := runConcurrentWorkersTest(db, dbType, memConfig)
	result.TestName = "Memory Pressure Test"
	return result
}

func runLongDurationTest(db *sql.DB, dbType string, config TestConfig) TestResult {
	// 长时间运行测试
	longConfig := config
	longConfig.TestDuration = 10 * time.Minute

	result := runHighThroughputTest(db, dbType, longConfig)
	result.TestName = "Long Duration Test"
	return result
}
